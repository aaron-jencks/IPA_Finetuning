{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "95cf754646879195"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-08T13:48:16.878943Z",
     "start_time": "2025-08-08T13:48:13.389360Z"
    }
   },
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "import wandb\n",
    "\n",
    "from hf_wrapper import GPTForSequenceClassification\n",
    "from tokenizer import load_character_tokenizer\n",
    "from utils import load_random_from_pretrained_model, compute_metrics, flatten_multi_features"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Variables",
   "id": "31d09c67930d6bcd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:48:16.884868Z",
     "start_time": "2025-08-08T13:48:16.882176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hf_cache = pathlib.Path('./cache')\n",
    "training_checkpoints = pathlib.Path('./cache/checkpoints')\n",
    "checkpoint = training_checkpoints / 'russian_polish_normal_12_5_50k' / 'ckpt.pt'\n",
    "tokenizer_prefix = pathlib.Path('./cache/tokenizers')\n",
    "ipa_tokenizer_path = tokenizer_prefix / 'hindi-urdu-character-tokenizer-ipa.json'\n",
    "normal_tokenizer_path = tokenizer_prefix / 'hindi-urdu-character-tokenizer-normal.json'\n",
    "\n",
    "dataset_name = {\n",
    "    'hin': \"krishnAbadikelA/hindi-xnli-ipa\",\n",
    "    'urd': \"krishnAbadikelA/urdu-xnli-ipa\"\n",
    "}\n",
    "\n",
    "epochs = 3\n",
    "context_size = 1024\n",
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "\n",
    "project_name = f\"debug-hindi-urdu-small-finetuning-xnli-random-initial-phonemizer\""
   ],
   "id": "f4836c09478871a5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Functions",
   "id": "a46a8bd8b11fd681"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:48:16.943210Z",
     "start_time": "2025-08-08T13:48:16.940175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_and_preprocess(lang: str, ipa: bool, split: str, tokenizer):\n",
    "    ds = load_dataset(dataset_name[lang], split=split, cache_dir=str(hf_cache))\n",
    "    column_names = ['premise', 'hypothesis']\n",
    "    suffix = 'phonemizer'\n",
    "    column_names = [(f'{column_name}-{suffix}' if ipa else column_name) for column_name in column_names]\n",
    "\n",
    "    def preprocess(examples):\n",
    "        features = flatten_multi_features(examples, column_names, sequence_token='<ENDOFTEXT>')\n",
    "        encoded = tokenizer(features, truncation=True, max_length=context_size)\n",
    "        encoded['label'] = examples['label']\n",
    "        return encoded\n",
    "\n",
    "    return ds.map(preprocess, batched=True, num_proc=os.cpu_count())"
   ],
   "id": "74c248242c4107e9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:48:16.991311Z",
     "start_time": "2025-08-08T13:48:16.984966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(lang: str, ipa: bool) -> Trainer:\n",
    "    temporary_output_dir = training_checkpoints / f\"{project_name}-{lang}-{'ipa' if ipa else 'normal'}/\"\n",
    "    temporary_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    vocab_path = ipa_tokenizer_path if ipa else normal_tokenizer_path\n",
    "    tokenizer = load_character_tokenizer(vocab_path)\n",
    "\n",
    "    base_model = load_random_from_pretrained_model(checkpoint, 'cuda')\n",
    "    base_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    base_model.config.padding_side = tokenizer.padding_side\n",
    "    model = GPTForSequenceClassification(base_model, num_classes=3).to('cuda')\n",
    "\n",
    "    if lang == 'hin':\n",
    "        train_dataset = load_and_preprocess('hin', ipa, 'train', tokenizer)\n",
    "        eval_dataset = load_and_preprocess('hin', ipa, 'validation', tokenizer)\n",
    "    elif lang == 'urd':\n",
    "        train_dataset = load_and_preprocess('urd', ipa, 'train', tokenizer)\n",
    "        eval_dataset = load_and_preprocess('urd', ipa, 'validation', tokenizer)\n",
    "    elif lang == 'both':\n",
    "        hin_train_dataset = load_and_preprocess('hin', ipa, 'train', tokenizer)\n",
    "        urd_train_dataset = load_and_preprocess('urd', ipa, 'train', tokenizer)\n",
    "        train_dataset = concatenate_datasets([hin_train_dataset, urd_train_dataset])\n",
    "\n",
    "        hin_eval_dataset = load_and_preprocess('hin', ipa, 'validation', tokenizer)\n",
    "        urd_eval_dataset = load_and_preprocess('urd', ipa, 'validation', tokenizer)\n",
    "        eval_dataset = concatenate_datasets([hin_eval_dataset, urd_eval_dataset])\n",
    "    else:\n",
    "        raise ValueError(f'Unknown train language: {lang}')\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=0.01,\n",
    "        output_dir=str(temporary_output_dir),\n",
    "        save_strategy='steps',\n",
    "        save_total_limit=1,\n",
    "        save_steps=0.01,\n",
    "        metric_for_best_model=\"precision\",\n",
    "        load_best_model_at_end=True,\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=0.01,\n",
    "        fp16=True,\n",
    "        warmup_ratio=0.3,\n",
    "        save_safetensors=False,\n",
    "        # disable_tqdm=True,\n",
    "    )\n",
    "\n",
    "    wrun = wandb.init(entity='aaronjencks-the-ohio-state-university', project=project_name, name=f'{lang}-{\"ipa\" if ipa else \"normal\"}')\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    print(f\"Training model\")\n",
    "    trainer.train()\n",
    "\n",
    "    wrun.finish()\n",
    "\n",
    "    return trainer"
   ],
   "id": "cb2e3890caf95fa1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:48:17.037147Z",
     "start_time": "2025-08-08T13:48:17.033475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def finetune_transcription(train_lang: str, eval_lang: str, ipa: bool, model: Trainer):\n",
    "    print('finetuning on {} {}'.format(eval_lang, 'ipa' if ipa else 'normal'))\n",
    "    vocab_path = ipa_tokenizer_path if ipa else normal_tokenizer_path\n",
    "    tokenizer = load_character_tokenizer(vocab_path)\n",
    "\n",
    "    if eval_lang == 'both':\n",
    "        hin_eval_dataset = load_and_preprocess('hin', ipa, 'validation', tokenizer)\n",
    "        urd_eval_dataset = load_and_preprocess('urd', ipa, 'validation', tokenizer)\n",
    "        eval_dataset = concatenate_datasets([hin_eval_dataset, urd_eval_dataset])\n",
    "    else:\n",
    "        eval_dataset = load_and_preprocess(eval_lang, ipa, 'validation', tokenizer)\n",
    "\n",
    "    wrun = wandb.init(entity='aaronjencks-the-ohio-state-university', project=project_name, name=f'{train_lang}-{eval_lang}-{\"ipa\" if ipa else \"normal\"}')\n",
    "\n",
    "    print(f\"Final evaluation on {eval_lang}\")\n",
    "    results = model.evaluate(eval_dataset=eval_dataset)\n",
    "    print(results)\n",
    "\n",
    "    wrun.finish()"
   ],
   "id": "582e6e8b069f11f5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Finetuning",
   "id": "2d89a4fd1e957012"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-08-08T13:48:17.084503Z"
    }
   },
   "cell_type": "code",
   "source": "model = train_model('hin', False)",
   "id": "39544e7cd35300f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 123.35M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33maaronjencks\u001B[0m (\u001B[33maaronjencks-the-ohio-state-university\u001B[0m) to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/workspace/github/IPA_Finetuning/wandb/run-20250808_094821-8plclasm</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-phonemizer/runs/8plclasm' target=\"_blank\">hin-normal</a></strong> to <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-phonemizer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-phonemizer' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-phonemizer</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-phonemizer/runs/8plclasm' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-phonemizer/runs/8plclasm</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1259616/2041274532.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1480' max='73632' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1480/73632 02:57 < 2:24:44, 8.31 it/s, Epoch 0.06/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>737</td>\n",
       "      <td>1.169900</td>\n",
       "      <td>1.138830</td>\n",
       "      <td>0.335743</td>\n",
       "      <td>0.336240</td>\n",
       "      <td>0.335743</td>\n",
       "      <td>0.331196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1474</td>\n",
       "      <td>1.131300</td>\n",
       "      <td>1.123982</td>\n",
       "      <td>0.343775</td>\n",
       "      <td>0.344032</td>\n",
       "      <td>0.343775</td>\n",
       "      <td>0.333005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:47:57.463616994Z",
     "start_time": "2025-08-05T15:54:26.048100Z"
    }
   },
   "cell_type": "code",
   "source": "finetune_transcription('hin', 'hin', False, model)",
   "id": "db29a78f54a11aad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuning on hin normal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/workspace/github/IPA_Finetuning/wandb/run-20250805_115427-lgmopj2r</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/lgmopj2r' target=\"_blank\">hin-hin-normal</a></strong> to <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/lgmopj2r' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/lgmopj2r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation on hin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1103460788726807, 'eval_accuracy': 0.40555555555555556, 'eval_precision': 0.4109192134565269, 'eval_recall': 0.40555555555555556, 'eval_f1': 0.38466769140682183, 'eval_runtime': 0.9409, 'eval_samples_per_second': 191.306, 'eval_steps_per_second': 12.754, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.40556</td></tr><tr><td>eval/f1</td><td>0.38467</td></tr><tr><td>eval/loss</td><td>1.11035</td></tr><tr><td>eval/precision</td><td>0.41092</td></tr><tr><td>eval/recall</td><td>0.40556</td></tr><tr><td>eval/runtime</td><td>0.9409</td></tr><tr><td>eval/samples_per_second</td><td>191.306</td></tr><tr><td>eval/steps_per_second</td><td>12.754</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>135</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hin-hin-normal</strong> at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/lgmopj2r' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/lgmopj2r</a><br> View project at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250805_115427-lgmopj2r/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:47:57.469453929Z",
     "start_time": "2025-08-05T15:55:12.002207Z"
    }
   },
   "cell_type": "code",
   "source": "model = train_model('hin', True)",
   "id": "61723d15faa40e0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 123.35M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/718 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5922eef973e6478788aa4d8cf025b609"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/180 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e8e64a4591f4ff4aa09f69c7b504b7e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/workspace/github/IPA_Finetuning/wandb/run-20250805_115517-yg8m2cyy</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/yg8m2cyy' target=\"_blank\">hin-ipa</a></strong> to <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/yg8m2cyy' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/yg8m2cyy</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_949323/2041274532.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [135/135 03:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.206700</td>\n",
       "      <td>1.168423</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.418428</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.366746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.204700</td>\n",
       "      <td>1.157199</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.414584</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.360936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.101400</td>\n",
       "      <td>1.148752</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.411047</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.369214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.140294</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.402689</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.364855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.989200</td>\n",
       "      <td>1.144377</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.420409</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.362910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.277000</td>\n",
       "      <td>1.145633</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.426023</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.356876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.113100</td>\n",
       "      <td>1.141759</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.409683</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.355025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.179300</td>\n",
       "      <td>1.135447</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.410995</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.358547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.102000</td>\n",
       "      <td>1.128776</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.411137</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.372985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.042800</td>\n",
       "      <td>1.140373</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.408202</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.362273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.180500</td>\n",
       "      <td>1.123203</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.391074</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.368733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.125500</td>\n",
       "      <td>1.115960</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.395052</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.352010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.218700</td>\n",
       "      <td>1.119838</td>\n",
       "      <td>0.338889</td>\n",
       "      <td>0.346380</td>\n",
       "      <td>0.338889</td>\n",
       "      <td>0.298158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.114200</td>\n",
       "      <td>1.124478</td>\n",
       "      <td>0.372222</td>\n",
       "      <td>0.374165</td>\n",
       "      <td>0.372222</td>\n",
       "      <td>0.262380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.119800</td>\n",
       "      <td>1.129768</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.280288</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.279904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.129300</td>\n",
       "      <td>1.161833</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.333337</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.286688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.100200</td>\n",
       "      <td>1.210316</td>\n",
       "      <td>0.294444</td>\n",
       "      <td>0.186236</td>\n",
       "      <td>0.294444</td>\n",
       "      <td>0.227205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.134200</td>\n",
       "      <td>1.218699</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.211266</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.253570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.122600</td>\n",
       "      <td>1.233855</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.210978</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.251540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.059400</td>\n",
       "      <td>1.283927</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.304854</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.209820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.107700</td>\n",
       "      <td>1.283290</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.328674</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.217989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.245800</td>\n",
       "      <td>1.229026</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.320613</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.313549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.252700</td>\n",
       "      <td>1.258615</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.340892</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.266626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.077300</td>\n",
       "      <td>1.341526</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.181111</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.195679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.050600</td>\n",
       "      <td>1.364946</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.118642</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.176492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.393800</td>\n",
       "      <td>1.328446</td>\n",
       "      <td>0.338889</td>\n",
       "      <td>0.191764</td>\n",
       "      <td>0.338889</td>\n",
       "      <td>0.193002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.070600</td>\n",
       "      <td>1.259165</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.314695</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.252545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.172600</td>\n",
       "      <td>1.243982</td>\n",
       "      <td>0.338889</td>\n",
       "      <td>0.370730</td>\n",
       "      <td>0.338889</td>\n",
       "      <td>0.304528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.149400</td>\n",
       "      <td>1.214498</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.367873</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.316094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.200300</td>\n",
       "      <td>1.189064</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.330828</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.315879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.152000</td>\n",
       "      <td>1.167240</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.310611</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.304999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.158500</td>\n",
       "      <td>1.171814</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.383964</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.317154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>1.194455</td>\n",
       "      <td>0.372222</td>\n",
       "      <td>0.416225</td>\n",
       "      <td>0.372222</td>\n",
       "      <td>0.277957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.067800</td>\n",
       "      <td>1.242079</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.415132</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.242684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.165500</td>\n",
       "      <td>1.225099</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.402377</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.250051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.141600</td>\n",
       "      <td>1.194038</td>\n",
       "      <td>0.338889</td>\n",
       "      <td>0.375107</td>\n",
       "      <td>0.338889</td>\n",
       "      <td>0.247084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.074500</td>\n",
       "      <td>1.141524</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.331807</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.274645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.136400</td>\n",
       "      <td>1.130924</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.340224</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.329397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.121100</td>\n",
       "      <td>1.137763</td>\n",
       "      <td>0.394444</td>\n",
       "      <td>0.397642</td>\n",
       "      <td>0.394444</td>\n",
       "      <td>0.393020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.958500</td>\n",
       "      <td>1.154511</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.373670</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.351344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1.071900</td>\n",
       "      <td>1.174799</td>\n",
       "      <td>0.338889</td>\n",
       "      <td>0.360318</td>\n",
       "      <td>0.338889</td>\n",
       "      <td>0.306957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>1.212500</td>\n",
       "      <td>1.177296</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.355650</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.306515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>1.095500</td>\n",
       "      <td>1.184303</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.351832</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.302299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.104600</td>\n",
       "      <td>1.193787</td>\n",
       "      <td>0.338889</td>\n",
       "      <td>0.357796</td>\n",
       "      <td>0.338889</td>\n",
       "      <td>0.312357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.198200</td>\n",
       "      <td>1.185531</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.349725</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.324535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.917400</td>\n",
       "      <td>1.195610</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.339785</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.277478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>1.004200</td>\n",
       "      <td>1.202246</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.326738</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.269403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.000500</td>\n",
       "      <td>1.206821</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.332432</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.277783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1.115500</td>\n",
       "      <td>1.203638</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.312493</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.266582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.107200</td>\n",
       "      <td>1.209791</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.312010</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.265026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.919300</td>\n",
       "      <td>1.226973</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.331937</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.275371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>1.184200</td>\n",
       "      <td>1.235923</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.392387</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.295250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>1.011100</td>\n",
       "      <td>1.235434</td>\n",
       "      <td>0.294444</td>\n",
       "      <td>0.316344</td>\n",
       "      <td>0.294444</td>\n",
       "      <td>0.252989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>1.125200</td>\n",
       "      <td>1.221003</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.320392</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.258399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.042900</td>\n",
       "      <td>1.202596</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.390794</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.301173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>1.093700</td>\n",
       "      <td>1.186956</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.337340</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.290089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>1.080800</td>\n",
       "      <td>1.182773</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.327058</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.305418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>1.051200</td>\n",
       "      <td>1.184231</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.339704</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.312269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>1.125800</td>\n",
       "      <td>1.184764</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.347642</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.308348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.138500</td>\n",
       "      <td>1.179073</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.320326</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.295127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>1.110800</td>\n",
       "      <td>1.172838</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.329350</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.312700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.983200</td>\n",
       "      <td>1.167923</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.333495</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.312614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>1.062300</td>\n",
       "      <td>1.165649</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.324037</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.306754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>1.124800</td>\n",
       "      <td>1.164856</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.321936</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.306021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.078900</td>\n",
       "      <td>1.165469</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.328858</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.312667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>1.027800</td>\n",
       "      <td>1.166432</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.349941</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.326213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>1.014800</td>\n",
       "      <td>1.166962</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.349941</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.326213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>██▇█▆▃▂▄▂▄▅▅▃▅▅▃▆▇▅▅▅█▄▄▅▃▃▃▁▁▅▂▃▃▄▄▃▃▄▄</td></tr><tr><td>eval/f1</td><td>▇▇▇▇▇▇▇▇▅▄▃▂▂▄▁▃▅▅▅▅▃▄█▇▅▅▅▆▄▃▃▃▅▄▅▅▅▅▅▆</td></tr><tr><td>eval/loss</td><td>▂▂▂▂▂▂▁▁▁▂▆▆▅▅█▅▅▄▃▃▅▄▂▁▂▃▃▃▃▃▄▅▄▄▃▃▃▃▃▃</td></tr><tr><td>eval/precision</td><td>█▇███▇▇▆▅▂▅▅▅▆▁▅▆▆██▇▅▆▇▇▆▆▅▅▅▇▅▅▇▅▅▅▅▅▆</td></tr><tr><td>eval/recall</td><td>██████▄▇▂▂▁▂▃▁▄▄▅▃▂▆▅▄▃▅▆▃▅▂▂▂▂▅▁▁▃▃▃▃▃▄</td></tr><tr><td>eval/runtime</td><td>▂▂▁▆▃▂▄▃▃▃▃▂▃▃▃▃▃▃▃▆▃▄▃▃▃▃▃▄▃▃▄▃▃▃▁█▄▄▇▃</td></tr><tr><td>eval/samples_per_second</td><td>▆██▂▆▅▇▇▄▆▆▆▆▆▆▆▆▆▆▆▆▅▁▆▄▅▅▆▅▅▄▅▆▅▅▄▄▄▄▅</td></tr><tr><td>eval/steps_per_second</td><td>▆▇█▇▅▇▇▇▇▅▆▆▆▆▆▆▆▆▆▆▆▃▅▅▆▆▆▆▆▅▆▆▅▆▆█▁▅▅▆</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>train/global_step</td><td>▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>train/grad_norm</td><td>▅▃▃▇▃▆▂▁▅▂▃▄▁▃▃▄▃▇▂▃▄▁▃▂▂▁▂▃▄▂▄▁▄▁▁█▃▂▂▃</td></tr><tr><td>train/learning_rate</td><td>▁▂▂▃▃▄▄▄▅▅▆▇████▇▇▇▇▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁</td></tr><tr><td>train/loss</td><td>▇▇▄█▆▃▆▅▇▅▅▄▅▇█▄▆▆▆▄▅▂▄▇▄▁▃▃▅▁▃▅▄▄▅▂▄▅▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.33333</td></tr><tr><td>eval/f1</td><td>0.32621</td></tr><tr><td>eval/loss</td><td>1.16696</td></tr><tr><td>eval/precision</td><td>0.34994</td></tr><tr><td>eval/recall</td><td>0.33333</td></tr><tr><td>eval/runtime</td><td>0.9225</td></tr><tr><td>eval/samples_per_second</td><td>195.121</td></tr><tr><td>eval/steps_per_second</td><td>13.008</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>135</td></tr><tr><td>train/grad_norm</td><td>7.90459</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.0148</td></tr><tr><td>train_loss</td><td>1.10813</td></tr><tr><td>train_runtime</td><td>209.9946</td></tr><tr><td>train_samples_per_second</td><td>10.257</td></tr><tr><td>train_steps_per_second</td><td>0.643</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hin-ipa</strong> at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/yg8m2cyy' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/yg8m2cyy</a><br> View project at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250805_115517-yg8m2cyy/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:47:57.516918950Z",
     "start_time": "2025-08-05T15:58:49.009617Z"
    }
   },
   "cell_type": "code",
   "source": "finetune_transcription('hin', 'hin', True, model)",
   "id": "e3ab18f3b9ed598",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuning on hin ipa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/workspace/github/IPA_Finetuning/wandb/run-20250805_115850-6b2dnl8k</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/6b2dnl8k' target=\"_blank\">hin-hin-ipa</a></strong> to <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/6b2dnl8k' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/6b2dnl8k</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation on hin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1456326246261597, 'eval_accuracy': 0.3888888888888889, 'eval_precision': 0.42602325083038683, 'eval_recall': 0.3888888888888889, 'eval_f1': 0.3568763059169542, 'eval_runtime': 0.9495, 'eval_samples_per_second': 189.573, 'eval_steps_per_second': 12.638, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.38889</td></tr><tr><td>eval/f1</td><td>0.35688</td></tr><tr><td>eval/loss</td><td>1.14563</td></tr><tr><td>eval/precision</td><td>0.42602</td></tr><tr><td>eval/recall</td><td>0.38889</td></tr><tr><td>eval/runtime</td><td>0.9495</td></tr><tr><td>eval/samples_per_second</td><td>189.573</td></tr><tr><td>eval/steps_per_second</td><td>12.638</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>135</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hin-hin-ipa</strong> at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/6b2dnl8k' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/6b2dnl8k</a><br> View project at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250805_115850-6b2dnl8k/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:47:57.519859298Z",
     "start_time": "2025-08-05T15:58:53.503981Z"
    }
   },
   "cell_type": "code",
   "source": "model = train_model('urd', False)",
   "id": "200ed61c8c3a14e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 123.35M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/10949 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c965dad535a4457b21183b96afc650d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating validation split:   0%|          | 0/2738 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "571eca85038a456c81f3a62ed848d06a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/10949 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "695d7d25e9854d319828225dd5f98b24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/2738 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0175774192c740a28db8e9e034b4d732"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/workspace/github/IPA_Finetuning/wandb/run-20250805_115859-tg89nmqn</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/tg89nmqn' target=\"_blank\">urd-normal</a></strong> to <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/tg89nmqn' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/tg89nmqn</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_949323/2041274532.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2055' max='2055' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2055/2055 07:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.127400</td>\n",
       "      <td>1.117578</td>\n",
       "      <td>0.398466</td>\n",
       "      <td>0.386979</td>\n",
       "      <td>0.398466</td>\n",
       "      <td>0.388329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.168500</td>\n",
       "      <td>1.063344</td>\n",
       "      <td>0.422571</td>\n",
       "      <td>0.407185</td>\n",
       "      <td>0.422571</td>\n",
       "      <td>0.409789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.048300</td>\n",
       "      <td>1.016537</td>\n",
       "      <td>0.445946</td>\n",
       "      <td>0.417976</td>\n",
       "      <td>0.445946</td>\n",
       "      <td>0.424700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>1.024500</td>\n",
       "      <td>0.993265</td>\n",
       "      <td>0.467495</td>\n",
       "      <td>0.441474</td>\n",
       "      <td>0.467495</td>\n",
       "      <td>0.443399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.014800</td>\n",
       "      <td>0.972458</td>\n",
       "      <td>0.486852</td>\n",
       "      <td>0.479213</td>\n",
       "      <td>0.486852</td>\n",
       "      <td>0.471848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>1.005600</td>\n",
       "      <td>0.959132</td>\n",
       "      <td>0.498904</td>\n",
       "      <td>0.488214</td>\n",
       "      <td>0.498904</td>\n",
       "      <td>0.486051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.973600</td>\n",
       "      <td>0.952819</td>\n",
       "      <td>0.480643</td>\n",
       "      <td>0.498217</td>\n",
       "      <td>0.480643</td>\n",
       "      <td>0.483690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.952500</td>\n",
       "      <td>0.931228</td>\n",
       "      <td>0.503287</td>\n",
       "      <td>0.482517</td>\n",
       "      <td>0.503287</td>\n",
       "      <td>0.483466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.996200</td>\n",
       "      <td>0.929042</td>\n",
       "      <td>0.510957</td>\n",
       "      <td>0.505904</td>\n",
       "      <td>0.510957</td>\n",
       "      <td>0.507826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.985500</td>\n",
       "      <td>0.942219</td>\n",
       "      <td>0.501096</td>\n",
       "      <td>0.492023</td>\n",
       "      <td>0.501096</td>\n",
       "      <td>0.447859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.942222</td>\n",
       "      <td>0.517531</td>\n",
       "      <td>0.511823</td>\n",
       "      <td>0.517531</td>\n",
       "      <td>0.477988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>0.938800</td>\n",
       "      <td>0.948617</td>\n",
       "      <td>0.490504</td>\n",
       "      <td>0.577493</td>\n",
       "      <td>0.490504</td>\n",
       "      <td>0.491883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>0.992600</td>\n",
       "      <td>0.959485</td>\n",
       "      <td>0.522279</td>\n",
       "      <td>0.507706</td>\n",
       "      <td>0.522279</td>\n",
       "      <td>0.478313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>0.967400</td>\n",
       "      <td>0.912114</td>\n",
       "      <td>0.542732</td>\n",
       "      <td>0.525480</td>\n",
       "      <td>0.542732</td>\n",
       "      <td>0.526279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>0.953800</td>\n",
       "      <td>0.950324</td>\n",
       "      <td>0.508035</td>\n",
       "      <td>0.543592</td>\n",
       "      <td>0.508035</td>\n",
       "      <td>0.516303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.928692</td>\n",
       "      <td>0.534697</td>\n",
       "      <td>0.517343</td>\n",
       "      <td>0.534697</td>\n",
       "      <td>0.499710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>357</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.934416</td>\n",
       "      <td>0.531045</td>\n",
       "      <td>0.503841</td>\n",
       "      <td>0.531045</td>\n",
       "      <td>0.497827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378</td>\n",
       "      <td>0.945800</td>\n",
       "      <td>0.908215</td>\n",
       "      <td>0.552958</td>\n",
       "      <td>0.542035</td>\n",
       "      <td>0.552958</td>\n",
       "      <td>0.542719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>1.004000</td>\n",
       "      <td>0.904687</td>\n",
       "      <td>0.540906</td>\n",
       "      <td>0.533518</td>\n",
       "      <td>0.540906</td>\n",
       "      <td>0.536165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.916400</td>\n",
       "      <td>0.915496</td>\n",
       "      <td>0.550037</td>\n",
       "      <td>0.538476</td>\n",
       "      <td>0.550037</td>\n",
       "      <td>0.522189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>441</td>\n",
       "      <td>0.944600</td>\n",
       "      <td>0.926784</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.555230</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.542676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.915405</td>\n",
       "      <td>0.543097</td>\n",
       "      <td>0.540911</td>\n",
       "      <td>0.543097</td>\n",
       "      <td>0.537311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>483</td>\n",
       "      <td>0.996800</td>\n",
       "      <td>0.900158</td>\n",
       "      <td>0.545654</td>\n",
       "      <td>0.548448</td>\n",
       "      <td>0.545654</td>\n",
       "      <td>0.544337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>0.963400</td>\n",
       "      <td>0.943049</td>\n",
       "      <td>0.529949</td>\n",
       "      <td>0.570331</td>\n",
       "      <td>0.529949</td>\n",
       "      <td>0.523720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.924200</td>\n",
       "      <td>0.909168</td>\n",
       "      <td>0.563550</td>\n",
       "      <td>0.549892</td>\n",
       "      <td>0.563550</td>\n",
       "      <td>0.549802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546</td>\n",
       "      <td>0.952900</td>\n",
       "      <td>0.935732</td>\n",
       "      <td>0.556976</td>\n",
       "      <td>0.552060</td>\n",
       "      <td>0.556976</td>\n",
       "      <td>0.526142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>0.900400</td>\n",
       "      <td>0.912912</td>\n",
       "      <td>0.548210</td>\n",
       "      <td>0.581421</td>\n",
       "      <td>0.548210</td>\n",
       "      <td>0.554573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>588</td>\n",
       "      <td>0.948600</td>\n",
       "      <td>0.896808</td>\n",
       "      <td>0.559533</td>\n",
       "      <td>0.564862</td>\n",
       "      <td>0.559533</td>\n",
       "      <td>0.555304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609</td>\n",
       "      <td>0.940600</td>\n",
       "      <td>0.912773</td>\n",
       "      <td>0.552593</td>\n",
       "      <td>0.580421</td>\n",
       "      <td>0.552593</td>\n",
       "      <td>0.540834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.986200</td>\n",
       "      <td>0.928152</td>\n",
       "      <td>0.553324</td>\n",
       "      <td>0.544921</td>\n",
       "      <td>0.553324</td>\n",
       "      <td>0.527962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>651</td>\n",
       "      <td>0.897700</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>0.549671</td>\n",
       "      <td>0.569513</td>\n",
       "      <td>0.549671</td>\n",
       "      <td>0.549302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>672</td>\n",
       "      <td>0.914900</td>\n",
       "      <td>0.927955</td>\n",
       "      <td>0.549306</td>\n",
       "      <td>0.536940</td>\n",
       "      <td>0.549306</td>\n",
       "      <td>0.505004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>693</td>\n",
       "      <td>0.996300</td>\n",
       "      <td>1.029369</td>\n",
       "      <td>0.488313</td>\n",
       "      <td>0.625025</td>\n",
       "      <td>0.488313</td>\n",
       "      <td>0.470631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>714</td>\n",
       "      <td>0.952800</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.545654</td>\n",
       "      <td>0.574527</td>\n",
       "      <td>0.545654</td>\n",
       "      <td>0.549588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>735</td>\n",
       "      <td>0.872300</td>\n",
       "      <td>0.898755</td>\n",
       "      <td>0.560628</td>\n",
       "      <td>0.565877</td>\n",
       "      <td>0.560628</td>\n",
       "      <td>0.552658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>756</td>\n",
       "      <td>0.907000</td>\n",
       "      <td>0.941765</td>\n",
       "      <td>0.540175</td>\n",
       "      <td>0.563040</td>\n",
       "      <td>0.540175</td>\n",
       "      <td>0.516533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>777</td>\n",
       "      <td>0.903700</td>\n",
       "      <td>0.907362</td>\n",
       "      <td>0.567933</td>\n",
       "      <td>0.572252</td>\n",
       "      <td>0.567933</td>\n",
       "      <td>0.566534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798</td>\n",
       "      <td>0.928400</td>\n",
       "      <td>0.887934</td>\n",
       "      <td>0.549306</td>\n",
       "      <td>0.553542</td>\n",
       "      <td>0.549306</td>\n",
       "      <td>0.551002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>819</td>\n",
       "      <td>0.844100</td>\n",
       "      <td>0.894783</td>\n",
       "      <td>0.564646</td>\n",
       "      <td>0.557364</td>\n",
       "      <td>0.564646</td>\n",
       "      <td>0.530360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.919700</td>\n",
       "      <td>0.873805</td>\n",
       "      <td>0.574872</td>\n",
       "      <td>0.574620</td>\n",
       "      <td>0.574872</td>\n",
       "      <td>0.570998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>861</td>\n",
       "      <td>0.857300</td>\n",
       "      <td>0.910182</td>\n",
       "      <td>0.546749</td>\n",
       "      <td>0.607442</td>\n",
       "      <td>0.546749</td>\n",
       "      <td>0.554543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>882</td>\n",
       "      <td>0.863700</td>\n",
       "      <td>0.868869</td>\n",
       "      <td>0.588751</td>\n",
       "      <td>0.587821</td>\n",
       "      <td>0.588751</td>\n",
       "      <td>0.586672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>903</td>\n",
       "      <td>0.896800</td>\n",
       "      <td>0.886195</td>\n",
       "      <td>0.575603</td>\n",
       "      <td>0.590168</td>\n",
       "      <td>0.575603</td>\n",
       "      <td>0.576012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>924</td>\n",
       "      <td>0.876700</td>\n",
       "      <td>0.861988</td>\n",
       "      <td>0.586194</td>\n",
       "      <td>0.575281</td>\n",
       "      <td>0.586194</td>\n",
       "      <td>0.564230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>945</td>\n",
       "      <td>0.846600</td>\n",
       "      <td>0.866249</td>\n",
       "      <td>0.577794</td>\n",
       "      <td>0.570397</td>\n",
       "      <td>0.577794</td>\n",
       "      <td>0.568310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>966</td>\n",
       "      <td>0.823500</td>\n",
       "      <td>0.863180</td>\n",
       "      <td>0.582177</td>\n",
       "      <td>0.574200</td>\n",
       "      <td>0.582177</td>\n",
       "      <td>0.572642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>987</td>\n",
       "      <td>0.844200</td>\n",
       "      <td>0.873332</td>\n",
       "      <td>0.585099</td>\n",
       "      <td>0.587427</td>\n",
       "      <td>0.585099</td>\n",
       "      <td>0.586048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1008</td>\n",
       "      <td>0.905200</td>\n",
       "      <td>0.864189</td>\n",
       "      <td>0.594229</td>\n",
       "      <td>0.590201</td>\n",
       "      <td>0.594229</td>\n",
       "      <td>0.570516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1029</td>\n",
       "      <td>0.905200</td>\n",
       "      <td>0.843551</td>\n",
       "      <td>0.598612</td>\n",
       "      <td>0.596590</td>\n",
       "      <td>0.598612</td>\n",
       "      <td>0.596224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.854300</td>\n",
       "      <td>0.856938</td>\n",
       "      <td>0.595325</td>\n",
       "      <td>0.594744</td>\n",
       "      <td>0.595325</td>\n",
       "      <td>0.580585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1071</td>\n",
       "      <td>0.861900</td>\n",
       "      <td>0.840531</td>\n",
       "      <td>0.598612</td>\n",
       "      <td>0.600219</td>\n",
       "      <td>0.598612</td>\n",
       "      <td>0.599199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1092</td>\n",
       "      <td>0.863600</td>\n",
       "      <td>0.859449</td>\n",
       "      <td>0.597151</td>\n",
       "      <td>0.606323</td>\n",
       "      <td>0.597151</td>\n",
       "      <td>0.597802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1113</td>\n",
       "      <td>0.844400</td>\n",
       "      <td>0.859471</td>\n",
       "      <td>0.598612</td>\n",
       "      <td>0.593529</td>\n",
       "      <td>0.598612</td>\n",
       "      <td>0.583934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1134</td>\n",
       "      <td>0.874400</td>\n",
       "      <td>0.857017</td>\n",
       "      <td>0.590942</td>\n",
       "      <td>0.604254</td>\n",
       "      <td>0.590942</td>\n",
       "      <td>0.592767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1155</td>\n",
       "      <td>0.892200</td>\n",
       "      <td>0.844190</td>\n",
       "      <td>0.600804</td>\n",
       "      <td>0.594031</td>\n",
       "      <td>0.600804</td>\n",
       "      <td>0.593133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1176</td>\n",
       "      <td>0.891200</td>\n",
       "      <td>0.844731</td>\n",
       "      <td>0.590942</td>\n",
       "      <td>0.590056</td>\n",
       "      <td>0.590942</td>\n",
       "      <td>0.590259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1197</td>\n",
       "      <td>0.837300</td>\n",
       "      <td>0.871639</td>\n",
       "      <td>0.585829</td>\n",
       "      <td>0.597863</td>\n",
       "      <td>0.585829</td>\n",
       "      <td>0.572514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1218</td>\n",
       "      <td>0.793100</td>\n",
       "      <td>0.849712</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.589302</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.590566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1239</td>\n",
       "      <td>0.898900</td>\n",
       "      <td>0.838422</td>\n",
       "      <td>0.599708</td>\n",
       "      <td>0.593560</td>\n",
       "      <td>0.599708</td>\n",
       "      <td>0.593171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>0.849642</td>\n",
       "      <td>0.593134</td>\n",
       "      <td>0.590659</td>\n",
       "      <td>0.593134</td>\n",
       "      <td>0.582076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1281</td>\n",
       "      <td>0.809600</td>\n",
       "      <td>0.839334</td>\n",
       "      <td>0.596056</td>\n",
       "      <td>0.593181</td>\n",
       "      <td>0.596056</td>\n",
       "      <td>0.593752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1302</td>\n",
       "      <td>0.881700</td>\n",
       "      <td>0.847689</td>\n",
       "      <td>0.597516</td>\n",
       "      <td>0.601514</td>\n",
       "      <td>0.597516</td>\n",
       "      <td>0.576848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1323</td>\n",
       "      <td>0.855500</td>\n",
       "      <td>0.842020</td>\n",
       "      <td>0.600438</td>\n",
       "      <td>0.615149</td>\n",
       "      <td>0.600438</td>\n",
       "      <td>0.602535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1344</td>\n",
       "      <td>0.841100</td>\n",
       "      <td>0.845605</td>\n",
       "      <td>0.599343</td>\n",
       "      <td>0.602067</td>\n",
       "      <td>0.599343</td>\n",
       "      <td>0.598525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1365</td>\n",
       "      <td>0.782300</td>\n",
       "      <td>0.845676</td>\n",
       "      <td>0.605551</td>\n",
       "      <td>0.605474</td>\n",
       "      <td>0.605551</td>\n",
       "      <td>0.592596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1386</td>\n",
       "      <td>0.817200</td>\n",
       "      <td>0.848020</td>\n",
       "      <td>0.606647</td>\n",
       "      <td>0.608121</td>\n",
       "      <td>0.606647</td>\n",
       "      <td>0.595719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1407</td>\n",
       "      <td>0.768600</td>\n",
       "      <td>0.847167</td>\n",
       "      <td>0.602630</td>\n",
       "      <td>0.615060</td>\n",
       "      <td>0.602630</td>\n",
       "      <td>0.602425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1428</td>\n",
       "      <td>0.804400</td>\n",
       "      <td>0.833891</td>\n",
       "      <td>0.608839</td>\n",
       "      <td>0.615998</td>\n",
       "      <td>0.608839</td>\n",
       "      <td>0.611379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1449</td>\n",
       "      <td>0.782700</td>\n",
       "      <td>0.829402</td>\n",
       "      <td>0.613952</td>\n",
       "      <td>0.614450</td>\n",
       "      <td>0.613952</td>\n",
       "      <td>0.611868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>0.721300</td>\n",
       "      <td>0.829703</td>\n",
       "      <td>0.609934</td>\n",
       "      <td>0.608178</td>\n",
       "      <td>0.609934</td>\n",
       "      <td>0.608277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1491</td>\n",
       "      <td>0.746100</td>\n",
       "      <td>0.827327</td>\n",
       "      <td>0.613587</td>\n",
       "      <td>0.612380</td>\n",
       "      <td>0.613587</td>\n",
       "      <td>0.611684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1512</td>\n",
       "      <td>0.728500</td>\n",
       "      <td>0.840194</td>\n",
       "      <td>0.611395</td>\n",
       "      <td>0.618060</td>\n",
       "      <td>0.611395</td>\n",
       "      <td>0.608841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1533</td>\n",
       "      <td>0.739000</td>\n",
       "      <td>0.846084</td>\n",
       "      <td>0.611030</td>\n",
       "      <td>0.605916</td>\n",
       "      <td>0.611030</td>\n",
       "      <td>0.597152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1554</td>\n",
       "      <td>0.822300</td>\n",
       "      <td>0.832227</td>\n",
       "      <td>0.616143</td>\n",
       "      <td>0.609528</td>\n",
       "      <td>0.616143</td>\n",
       "      <td>0.607082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>0.785600</td>\n",
       "      <td>0.839674</td>\n",
       "      <td>0.616874</td>\n",
       "      <td>0.620388</td>\n",
       "      <td>0.616874</td>\n",
       "      <td>0.616636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1596</td>\n",
       "      <td>0.796800</td>\n",
       "      <td>0.819892</td>\n",
       "      <td>0.626370</td>\n",
       "      <td>0.624702</td>\n",
       "      <td>0.626370</td>\n",
       "      <td>0.625424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1617</td>\n",
       "      <td>0.836100</td>\n",
       "      <td>0.824105</td>\n",
       "      <td>0.614317</td>\n",
       "      <td>0.613983</td>\n",
       "      <td>0.614317</td>\n",
       "      <td>0.611220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1638</td>\n",
       "      <td>0.769200</td>\n",
       "      <td>0.826041</td>\n",
       "      <td>0.616508</td>\n",
       "      <td>0.618963</td>\n",
       "      <td>0.616508</td>\n",
       "      <td>0.615974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1659</td>\n",
       "      <td>0.771400</td>\n",
       "      <td>0.823692</td>\n",
       "      <td>0.611030</td>\n",
       "      <td>0.607513</td>\n",
       "      <td>0.611030</td>\n",
       "      <td>0.608026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.745700</td>\n",
       "      <td>0.824142</td>\n",
       "      <td>0.619795</td>\n",
       "      <td>0.614297</td>\n",
       "      <td>0.619795</td>\n",
       "      <td>0.611588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1701</td>\n",
       "      <td>0.801900</td>\n",
       "      <td>0.831614</td>\n",
       "      <td>0.605917</td>\n",
       "      <td>0.615180</td>\n",
       "      <td>0.605917</td>\n",
       "      <td>0.607456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1722</td>\n",
       "      <td>0.725300</td>\n",
       "      <td>0.827804</td>\n",
       "      <td>0.620526</td>\n",
       "      <td>0.618095</td>\n",
       "      <td>0.620526</td>\n",
       "      <td>0.614312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1743</td>\n",
       "      <td>0.766100</td>\n",
       "      <td>0.821883</td>\n",
       "      <td>0.622352</td>\n",
       "      <td>0.616963</td>\n",
       "      <td>0.622352</td>\n",
       "      <td>0.615574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1764</td>\n",
       "      <td>0.757500</td>\n",
       "      <td>0.818110</td>\n",
       "      <td>0.624909</td>\n",
       "      <td>0.624985</td>\n",
       "      <td>0.624909</td>\n",
       "      <td>0.620172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1785</td>\n",
       "      <td>0.727100</td>\n",
       "      <td>0.819154</td>\n",
       "      <td>0.624909</td>\n",
       "      <td>0.624414</td>\n",
       "      <td>0.624909</td>\n",
       "      <td>0.623582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1806</td>\n",
       "      <td>0.771800</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.623813</td>\n",
       "      <td>0.621393</td>\n",
       "      <td>0.623813</td>\n",
       "      <td>0.618228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1827</td>\n",
       "      <td>0.768100</td>\n",
       "      <td>0.810521</td>\n",
       "      <td>0.629291</td>\n",
       "      <td>0.629800</td>\n",
       "      <td>0.629291</td>\n",
       "      <td>0.629396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1848</td>\n",
       "      <td>0.756400</td>\n",
       "      <td>0.813740</td>\n",
       "      <td>0.624543</td>\n",
       "      <td>0.628026</td>\n",
       "      <td>0.624543</td>\n",
       "      <td>0.625798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1869</td>\n",
       "      <td>0.781600</td>\n",
       "      <td>0.810981</td>\n",
       "      <td>0.631848</td>\n",
       "      <td>0.630404</td>\n",
       "      <td>0.631848</td>\n",
       "      <td>0.628427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>0.759500</td>\n",
       "      <td>0.808649</td>\n",
       "      <td>0.631118</td>\n",
       "      <td>0.628307</td>\n",
       "      <td>0.631118</td>\n",
       "      <td>0.628070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1911</td>\n",
       "      <td>0.757600</td>\n",
       "      <td>0.817901</td>\n",
       "      <td>0.627100</td>\n",
       "      <td>0.629287</td>\n",
       "      <td>0.627100</td>\n",
       "      <td>0.622491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1932</td>\n",
       "      <td>0.695200</td>\n",
       "      <td>0.815162</td>\n",
       "      <td>0.627465</td>\n",
       "      <td>0.624421</td>\n",
       "      <td>0.627465</td>\n",
       "      <td>0.620516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1953</td>\n",
       "      <td>0.761500</td>\n",
       "      <td>0.808395</td>\n",
       "      <td>0.632213</td>\n",
       "      <td>0.627789</td>\n",
       "      <td>0.632213</td>\n",
       "      <td>0.628536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1974</td>\n",
       "      <td>0.742400</td>\n",
       "      <td>0.808093</td>\n",
       "      <td>0.630022</td>\n",
       "      <td>0.628851</td>\n",
       "      <td>0.630022</td>\n",
       "      <td>0.629264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>0.727900</td>\n",
       "      <td>0.808730</td>\n",
       "      <td>0.631118</td>\n",
       "      <td>0.631808</td>\n",
       "      <td>0.631118</td>\n",
       "      <td>0.631177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016</td>\n",
       "      <td>0.726500</td>\n",
       "      <td>0.809861</td>\n",
       "      <td>0.628926</td>\n",
       "      <td>0.632137</td>\n",
       "      <td>0.628926</td>\n",
       "      <td>0.629773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2037</td>\n",
       "      <td>0.715600</td>\n",
       "      <td>0.808695</td>\n",
       "      <td>0.631118</td>\n",
       "      <td>0.632017</td>\n",
       "      <td>0.631118</td>\n",
       "      <td>0.630729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▃▃▄▃▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▇▆▆▇▇▇▇▇▇▇▇█▇███████</td></tr><tr><td>eval/f1</td><td>▁▃▄▄▃▄▄▅▅▆▆▆▅▆▄▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>eval/loss</td><td>█▆▆▅▅▄▅▅▄▄▅▄▅▄▅█▅▄▃▄▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▃▃▆▄▄▅▅▅▅▅█▆▆▆▆▆▆▆▆▇▇▇▇▇▆▇▇▇▇▇██▇▇█████</td></tr><tr><td>eval/recall</td><td>▁▂▂▃▃▂▃▄▃▄▄▅▄▄▅▄▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇█▇▇▇█████</td></tr><tr><td>eval/runtime</td><td>▄▁▃▁▇▄▁▆▆▂▂▁▄█▂▁▃▂▁▃▅▃▁▂▁▃▇▂▂▃▂▇▁▂▃▄▂▃▂▂</td></tr><tr><td>eval/samples_per_second</td><td>▃▂█▆▆▂▆▅█▇▇▆▅█▇█▆██▆▄▄██▅█▂▇▃▇▇▆▇▂▇▅▇█▇▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁▄▆▆█▄▄█▄▇▇▇█▆▇▆▇██▅▄▆█▆▇▂▇▅▇▇▇▅▇█▃▇▇▅▃</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▂▂▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇█</td></tr><tr><td>train/grad_norm</td><td>▃█▅▆▃▇▄█▅▆▄▅▂▂▃▄▅▃▂▁▁▇▁▃▂▁▂▄▂▁▂▃▂▂▃▄▂▂▅▂</td></tr><tr><td>train/learning_rate</td><td>▁▂▃▄▅▅▆▆▆▇████▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▆▆▅▅▅▅▆▅▅▅▄▅▄▄▄▄▃▃▄▄▄▃▄▄▃▃▂▃▂▃▃▃▂▂▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.63112</td></tr><tr><td>eval/f1</td><td>0.63073</td></tr><tr><td>eval/loss</td><td>0.8087</td></tr><tr><td>eval/precision</td><td>0.63202</td></tr><tr><td>eval/recall</td><td>0.63112</td></tr><tr><td>eval/runtime</td><td>1.8334</td></tr><tr><td>eval/samples_per_second</td><td>1493.425</td></tr><tr><td>eval/steps_per_second</td><td>93.816</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>2055</td></tr><tr><td>train/grad_norm</td><td>5.36384</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7156</td></tr><tr><td>train_loss</td><td>0.86932</td></tr><tr><td>train_runtime</td><td>456.5196</td></tr><tr><td>train_samples_per_second</td><td>71.951</td></tr><tr><td>train_steps_per_second</td><td>4.501</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">urd-normal</strong> at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/tg89nmqn' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/tg89nmqn</a><br> View project at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250805_115859-tg89nmqn/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:47:57.530260258Z",
     "start_time": "2025-08-05T16:06:37.943611Z"
    }
   },
   "cell_type": "code",
   "source": "finetune_transcription('urd', 'urd', False, model)",
   "id": "a6148462e4892d6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuning on urd normal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/workspace/github/IPA_Finetuning/wandb/run-20250805_120639-kdz1kyrg</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/kdz1kyrg' target=\"_blank\">urd-urd-normal</a></strong> to <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/kdz1kyrg' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/kdz1kyrg</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation on urd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='172' max='172' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [172/172 00:01]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8098613619804382, 'eval_accuracy': 0.6289262235208181, 'eval_precision': 0.6321365985140542, 'eval_recall': 0.6289262235208181, 'eval_f1': 0.6297725883329489, 'eval_runtime': 1.9213, 'eval_samples_per_second': 1425.087, 'eval_steps_per_second': 89.523, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.62893</td></tr><tr><td>eval/f1</td><td>0.62977</td></tr><tr><td>eval/loss</td><td>0.80986</td></tr><tr><td>eval/precision</td><td>0.63214</td></tr><tr><td>eval/recall</td><td>0.62893</td></tr><tr><td>eval/runtime</td><td>1.9213</td></tr><tr><td>eval/samples_per_second</td><td>1425.087</td></tr><tr><td>eval/steps_per_second</td><td>89.523</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>2055</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">urd-urd-normal</strong> at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/kdz1kyrg' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/kdz1kyrg</a><br> View project at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250805_120639-kdz1kyrg/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:47:57.530877647Z",
     "start_time": "2025-08-05T16:06:42.807752Z"
    }
   },
   "cell_type": "code",
   "source": "model = train_model('urd', True)",
   "id": "6bbbe22ac3d7e73b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 123.35M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/10949 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69a40561ffb84ae9a93546f7570d11da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/2738 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6076c79267e4643aba742609a34b517"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/workspace/github/IPA_Finetuning/wandb/run-20250805_120648-sx1hrrqj</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/sx1hrrqj' target=\"_blank\">urd-ipa</a></strong> to <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/sx1hrrqj' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/sx1hrrqj</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_949323/2041274532.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2055' max='2055' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2055/2055 08:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.160400</td>\n",
       "      <td>1.128288</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.345556</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.345868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.132700</td>\n",
       "      <td>1.110017</td>\n",
       "      <td>0.405040</td>\n",
       "      <td>0.360176</td>\n",
       "      <td>0.405040</td>\n",
       "      <td>0.358687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.123100</td>\n",
       "      <td>1.106823</td>\n",
       "      <td>0.394449</td>\n",
       "      <td>0.363025</td>\n",
       "      <td>0.394449</td>\n",
       "      <td>0.370235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>1.130600</td>\n",
       "      <td>1.097492</td>\n",
       "      <td>0.407962</td>\n",
       "      <td>0.370738</td>\n",
       "      <td>0.407962</td>\n",
       "      <td>0.374601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.088800</td>\n",
       "      <td>1.103557</td>\n",
       "      <td>0.385683</td>\n",
       "      <td>0.378156</td>\n",
       "      <td>0.385683</td>\n",
       "      <td>0.353834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>1.142300</td>\n",
       "      <td>1.079785</td>\n",
       "      <td>0.432798</td>\n",
       "      <td>0.398251</td>\n",
       "      <td>0.432798</td>\n",
       "      <td>0.395080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.076625</td>\n",
       "      <td>0.436815</td>\n",
       "      <td>0.420003</td>\n",
       "      <td>0.436815</td>\n",
       "      <td>0.375179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>1.072800</td>\n",
       "      <td>1.065400</td>\n",
       "      <td>0.464573</td>\n",
       "      <td>0.447882</td>\n",
       "      <td>0.464573</td>\n",
       "      <td>0.356416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>1.086000</td>\n",
       "      <td>1.059854</td>\n",
       "      <td>0.445581</td>\n",
       "      <td>0.423039</td>\n",
       "      <td>0.445581</td>\n",
       "      <td>0.410816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.056600</td>\n",
       "      <td>1.091164</td>\n",
       "      <td>0.454711</td>\n",
       "      <td>0.484145</td>\n",
       "      <td>0.454711</td>\n",
       "      <td>0.306970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>1.020800</td>\n",
       "      <td>1.067449</td>\n",
       "      <td>0.467129</td>\n",
       "      <td>0.456064</td>\n",
       "      <td>0.467129</td>\n",
       "      <td>0.403937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>1.046900</td>\n",
       "      <td>1.054516</td>\n",
       "      <td>0.448868</td>\n",
       "      <td>0.431940</td>\n",
       "      <td>0.448868</td>\n",
       "      <td>0.421259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>1.027400</td>\n",
       "      <td>1.058695</td>\n",
       "      <td>0.481738</td>\n",
       "      <td>0.448536</td>\n",
       "      <td>0.481738</td>\n",
       "      <td>0.416012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>1.086700</td>\n",
       "      <td>1.045641</td>\n",
       "      <td>0.485026</td>\n",
       "      <td>0.454195</td>\n",
       "      <td>0.485026</td>\n",
       "      <td>0.426300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>1.046600</td>\n",
       "      <td>1.011714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.482955</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.484903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336</td>\n",
       "      <td>1.067500</td>\n",
       "      <td>1.013727</td>\n",
       "      <td>0.493791</td>\n",
       "      <td>0.474806</td>\n",
       "      <td>0.493791</td>\n",
       "      <td>0.463525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>357</td>\n",
       "      <td>1.039000</td>\n",
       "      <td>1.028491</td>\n",
       "      <td>0.496713</td>\n",
       "      <td>0.481128</td>\n",
       "      <td>0.496713</td>\n",
       "      <td>0.395476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378</td>\n",
       "      <td>1.032500</td>\n",
       "      <td>1.041323</td>\n",
       "      <td>0.492695</td>\n",
       "      <td>0.454705</td>\n",
       "      <td>0.492695</td>\n",
       "      <td>0.385516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>1.047700</td>\n",
       "      <td>1.029440</td>\n",
       "      <td>0.493061</td>\n",
       "      <td>0.503489</td>\n",
       "      <td>0.493061</td>\n",
       "      <td>0.407070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.036200</td>\n",
       "      <td>0.994139</td>\n",
       "      <td>0.519357</td>\n",
       "      <td>0.485707</td>\n",
       "      <td>0.519357</td>\n",
       "      <td>0.446707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>441</td>\n",
       "      <td>1.038600</td>\n",
       "      <td>1.032507</td>\n",
       "      <td>0.474434</td>\n",
       "      <td>0.502798</td>\n",
       "      <td>0.474434</td>\n",
       "      <td>0.452845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462</td>\n",
       "      <td>1.008900</td>\n",
       "      <td>0.972220</td>\n",
       "      <td>0.528488</td>\n",
       "      <td>0.510639</td>\n",
       "      <td>0.528488</td>\n",
       "      <td>0.501161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>483</td>\n",
       "      <td>1.087500</td>\n",
       "      <td>1.017360</td>\n",
       "      <td>0.506209</td>\n",
       "      <td>0.548064</td>\n",
       "      <td>0.506209</td>\n",
       "      <td>0.439255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>0.991600</td>\n",
       "      <td>1.008509</td>\n",
       "      <td>0.494887</td>\n",
       "      <td>0.537411</td>\n",
       "      <td>0.494887</td>\n",
       "      <td>0.468502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>1.018300</td>\n",
       "      <td>0.968830</td>\n",
       "      <td>0.528853</td>\n",
       "      <td>0.527027</td>\n",
       "      <td>0.528853</td>\n",
       "      <td>0.527383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546</td>\n",
       "      <td>1.038900</td>\n",
       "      <td>0.974399</td>\n",
       "      <td>0.522644</td>\n",
       "      <td>0.526898</td>\n",
       "      <td>0.522644</td>\n",
       "      <td>0.505868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>1.004500</td>\n",
       "      <td>1.016886</td>\n",
       "      <td>0.493061</td>\n",
       "      <td>0.564226</td>\n",
       "      <td>0.493061</td>\n",
       "      <td>0.496869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>588</td>\n",
       "      <td>0.989700</td>\n",
       "      <td>0.958574</td>\n",
       "      <td>0.521914</td>\n",
       "      <td>0.532322</td>\n",
       "      <td>0.521914</td>\n",
       "      <td>0.513126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609</td>\n",
       "      <td>0.994900</td>\n",
       "      <td>0.951884</td>\n",
       "      <td>0.541636</td>\n",
       "      <td>0.532717</td>\n",
       "      <td>0.541636</td>\n",
       "      <td>0.509473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.018800</td>\n",
       "      <td>0.971273</td>\n",
       "      <td>0.521183</td>\n",
       "      <td>0.527610</td>\n",
       "      <td>0.521183</td>\n",
       "      <td>0.442337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>651</td>\n",
       "      <td>0.965600</td>\n",
       "      <td>0.986557</td>\n",
       "      <td>0.516801</td>\n",
       "      <td>0.528559</td>\n",
       "      <td>0.516801</td>\n",
       "      <td>0.508648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>672</td>\n",
       "      <td>0.954100</td>\n",
       "      <td>0.964372</td>\n",
       "      <td>0.547845</td>\n",
       "      <td>0.533712</td>\n",
       "      <td>0.547845</td>\n",
       "      <td>0.495835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>693</td>\n",
       "      <td>1.001100</td>\n",
       "      <td>1.167727</td>\n",
       "      <td>0.387144</td>\n",
       "      <td>0.596574</td>\n",
       "      <td>0.387144</td>\n",
       "      <td>0.306529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>714</td>\n",
       "      <td>0.961600</td>\n",
       "      <td>0.933462</td>\n",
       "      <td>0.554785</td>\n",
       "      <td>0.544011</td>\n",
       "      <td>0.554785</td>\n",
       "      <td>0.544963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>735</td>\n",
       "      <td>0.954900</td>\n",
       "      <td>0.931682</td>\n",
       "      <td>0.554419</td>\n",
       "      <td>0.544001</td>\n",
       "      <td>0.554419</td>\n",
       "      <td>0.538053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>756</td>\n",
       "      <td>0.972800</td>\n",
       "      <td>1.003285</td>\n",
       "      <td>0.529949</td>\n",
       "      <td>0.578275</td>\n",
       "      <td>0.529949</td>\n",
       "      <td>0.480359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>777</td>\n",
       "      <td>0.945600</td>\n",
       "      <td>0.927307</td>\n",
       "      <td>0.557706</td>\n",
       "      <td>0.553740</td>\n",
       "      <td>0.557706</td>\n",
       "      <td>0.534577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798</td>\n",
       "      <td>0.927800</td>\n",
       "      <td>0.951723</td>\n",
       "      <td>0.561359</td>\n",
       "      <td>0.558394</td>\n",
       "      <td>0.561359</td>\n",
       "      <td>0.529891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>819</td>\n",
       "      <td>1.001100</td>\n",
       "      <td>0.942199</td>\n",
       "      <td>0.555150</td>\n",
       "      <td>0.552610</td>\n",
       "      <td>0.555150</td>\n",
       "      <td>0.514379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>0.964797</td>\n",
       "      <td>0.548576</td>\n",
       "      <td>0.574286</td>\n",
       "      <td>0.548576</td>\n",
       "      <td>0.501613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>861</td>\n",
       "      <td>0.955100</td>\n",
       "      <td>0.930057</td>\n",
       "      <td>0.562820</td>\n",
       "      <td>0.562025</td>\n",
       "      <td>0.562820</td>\n",
       "      <td>0.555138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>882</td>\n",
       "      <td>0.957400</td>\n",
       "      <td>0.966769</td>\n",
       "      <td>0.539445</td>\n",
       "      <td>0.571181</td>\n",
       "      <td>0.539445</td>\n",
       "      <td>0.532699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>903</td>\n",
       "      <td>0.928700</td>\n",
       "      <td>0.956331</td>\n",
       "      <td>0.539080</td>\n",
       "      <td>0.581943</td>\n",
       "      <td>0.539080</td>\n",
       "      <td>0.543262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>924</td>\n",
       "      <td>0.971500</td>\n",
       "      <td>0.921627</td>\n",
       "      <td>0.547845</td>\n",
       "      <td>0.568244</td>\n",
       "      <td>0.547845</td>\n",
       "      <td>0.485731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>945</td>\n",
       "      <td>0.882700</td>\n",
       "      <td>0.931399</td>\n",
       "      <td>0.546749</td>\n",
       "      <td>0.579332</td>\n",
       "      <td>0.546749</td>\n",
       "      <td>0.478780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>966</td>\n",
       "      <td>0.938200</td>\n",
       "      <td>0.908660</td>\n",
       "      <td>0.575968</td>\n",
       "      <td>0.568974</td>\n",
       "      <td>0.575968</td>\n",
       "      <td>0.549014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>987</td>\n",
       "      <td>0.913100</td>\n",
       "      <td>0.906265</td>\n",
       "      <td>0.582542</td>\n",
       "      <td>0.579461</td>\n",
       "      <td>0.582542</td>\n",
       "      <td>0.576816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1008</td>\n",
       "      <td>0.952100</td>\n",
       "      <td>0.962716</td>\n",
       "      <td>0.537619</td>\n",
       "      <td>0.578676</td>\n",
       "      <td>0.537619</td>\n",
       "      <td>0.467411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1029</td>\n",
       "      <td>0.964700</td>\n",
       "      <td>0.920585</td>\n",
       "      <td>0.569759</td>\n",
       "      <td>0.596884</td>\n",
       "      <td>0.569759</td>\n",
       "      <td>0.531555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.912800</td>\n",
       "      <td>0.904779</td>\n",
       "      <td>0.587290</td>\n",
       "      <td>0.591436</td>\n",
       "      <td>0.587290</td>\n",
       "      <td>0.571463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1071</td>\n",
       "      <td>0.921200</td>\n",
       "      <td>0.908442</td>\n",
       "      <td>0.573046</td>\n",
       "      <td>0.572467</td>\n",
       "      <td>0.573046</td>\n",
       "      <td>0.572706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1092</td>\n",
       "      <td>0.937200</td>\n",
       "      <td>0.905662</td>\n",
       "      <td>0.578524</td>\n",
       "      <td>0.575463</td>\n",
       "      <td>0.578524</td>\n",
       "      <td>0.572170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1113</td>\n",
       "      <td>0.884800</td>\n",
       "      <td>0.906085</td>\n",
       "      <td>0.577064</td>\n",
       "      <td>0.588895</td>\n",
       "      <td>0.577064</td>\n",
       "      <td>0.542805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1134</td>\n",
       "      <td>0.952700</td>\n",
       "      <td>0.896137</td>\n",
       "      <td>0.588020</td>\n",
       "      <td>0.583272</td>\n",
       "      <td>0.588020</td>\n",
       "      <td>0.580798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1155</td>\n",
       "      <td>0.953200</td>\n",
       "      <td>0.892655</td>\n",
       "      <td>0.588020</td>\n",
       "      <td>0.586409</td>\n",
       "      <td>0.588020</td>\n",
       "      <td>0.565588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1176</td>\n",
       "      <td>0.961000</td>\n",
       "      <td>0.892568</td>\n",
       "      <td>0.588751</td>\n",
       "      <td>0.585164</td>\n",
       "      <td>0.588751</td>\n",
       "      <td>0.586154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1197</td>\n",
       "      <td>0.891600</td>\n",
       "      <td>0.957707</td>\n",
       "      <td>0.546384</td>\n",
       "      <td>0.603807</td>\n",
       "      <td>0.546384</td>\n",
       "      <td>0.497470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1218</td>\n",
       "      <td>0.875500</td>\n",
       "      <td>0.891115</td>\n",
       "      <td>0.585099</td>\n",
       "      <td>0.580740</td>\n",
       "      <td>0.585099</td>\n",
       "      <td>0.576481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1239</td>\n",
       "      <td>0.957400</td>\n",
       "      <td>0.891208</td>\n",
       "      <td>0.589116</td>\n",
       "      <td>0.583479</td>\n",
       "      <td>0.589116</td>\n",
       "      <td>0.583219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.868800</td>\n",
       "      <td>0.937072</td>\n",
       "      <td>0.566107</td>\n",
       "      <td>0.589671</td>\n",
       "      <td>0.566107</td>\n",
       "      <td>0.541765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1281</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.888366</td>\n",
       "      <td>0.591308</td>\n",
       "      <td>0.589097</td>\n",
       "      <td>0.591308</td>\n",
       "      <td>0.586770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1302</td>\n",
       "      <td>0.978900</td>\n",
       "      <td>0.899868</td>\n",
       "      <td>0.579985</td>\n",
       "      <td>0.585476</td>\n",
       "      <td>0.579985</td>\n",
       "      <td>0.537160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1323</td>\n",
       "      <td>0.921300</td>\n",
       "      <td>0.911927</td>\n",
       "      <td>0.577429</td>\n",
       "      <td>0.595587</td>\n",
       "      <td>0.577429</td>\n",
       "      <td>0.577741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1344</td>\n",
       "      <td>0.918200</td>\n",
       "      <td>0.898598</td>\n",
       "      <td>0.589481</td>\n",
       "      <td>0.595804</td>\n",
       "      <td>0.589481</td>\n",
       "      <td>0.579567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1365</td>\n",
       "      <td>0.887400</td>\n",
       "      <td>0.894249</td>\n",
       "      <td>0.585829</td>\n",
       "      <td>0.587851</td>\n",
       "      <td>0.585829</td>\n",
       "      <td>0.562522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1386</td>\n",
       "      <td>0.873300</td>\n",
       "      <td>0.892418</td>\n",
       "      <td>0.589481</td>\n",
       "      <td>0.597265</td>\n",
       "      <td>0.589481</td>\n",
       "      <td>0.570465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1407</td>\n",
       "      <td>0.856500</td>\n",
       "      <td>0.879466</td>\n",
       "      <td>0.605186</td>\n",
       "      <td>0.599805</td>\n",
       "      <td>0.605186</td>\n",
       "      <td>0.594787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1428</td>\n",
       "      <td>0.851000</td>\n",
       "      <td>0.910010</td>\n",
       "      <td>0.580716</td>\n",
       "      <td>0.589832</td>\n",
       "      <td>0.580716</td>\n",
       "      <td>0.574398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1449</td>\n",
       "      <td>0.903600</td>\n",
       "      <td>0.878630</td>\n",
       "      <td>0.603725</td>\n",
       "      <td>0.601011</td>\n",
       "      <td>0.603725</td>\n",
       "      <td>0.590513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>0.833600</td>\n",
       "      <td>0.876752</td>\n",
       "      <td>0.605186</td>\n",
       "      <td>0.605570</td>\n",
       "      <td>0.605186</td>\n",
       "      <td>0.586834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1491</td>\n",
       "      <td>0.834200</td>\n",
       "      <td>0.875223</td>\n",
       "      <td>0.604091</td>\n",
       "      <td>0.601164</td>\n",
       "      <td>0.604091</td>\n",
       "      <td>0.590239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1512</td>\n",
       "      <td>0.861900</td>\n",
       "      <td>0.886595</td>\n",
       "      <td>0.586560</td>\n",
       "      <td>0.596258</td>\n",
       "      <td>0.586560</td>\n",
       "      <td>0.587891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1533</td>\n",
       "      <td>0.843200</td>\n",
       "      <td>0.897679</td>\n",
       "      <td>0.593864</td>\n",
       "      <td>0.598139</td>\n",
       "      <td>0.593864</td>\n",
       "      <td>0.588233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1554</td>\n",
       "      <td>0.895600</td>\n",
       "      <td>0.878665</td>\n",
       "      <td>0.597882</td>\n",
       "      <td>0.597270</td>\n",
       "      <td>0.597882</td>\n",
       "      <td>0.586649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.883406</td>\n",
       "      <td>0.601169</td>\n",
       "      <td>0.600491</td>\n",
       "      <td>0.601169</td>\n",
       "      <td>0.585910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1596</td>\n",
       "      <td>0.830900</td>\n",
       "      <td>0.911459</td>\n",
       "      <td>0.573046</td>\n",
       "      <td>0.601124</td>\n",
       "      <td>0.573046</td>\n",
       "      <td>0.576221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1617</td>\n",
       "      <td>0.856900</td>\n",
       "      <td>0.883827</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.597329</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.581412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1638</td>\n",
       "      <td>0.824600</td>\n",
       "      <td>0.876675</td>\n",
       "      <td>0.602264</td>\n",
       "      <td>0.599244</td>\n",
       "      <td>0.602264</td>\n",
       "      <td>0.600056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1659</td>\n",
       "      <td>0.843500</td>\n",
       "      <td>0.872338</td>\n",
       "      <td>0.603360</td>\n",
       "      <td>0.599771</td>\n",
       "      <td>0.603360</td>\n",
       "      <td>0.592067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.803100</td>\n",
       "      <td>0.882856</td>\n",
       "      <td>0.602630</td>\n",
       "      <td>0.601946</td>\n",
       "      <td>0.602630</td>\n",
       "      <td>0.594605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1701</td>\n",
       "      <td>0.858900</td>\n",
       "      <td>0.883461</td>\n",
       "      <td>0.605551</td>\n",
       "      <td>0.606998</td>\n",
       "      <td>0.605551</td>\n",
       "      <td>0.604226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1722</td>\n",
       "      <td>0.785600</td>\n",
       "      <td>0.885901</td>\n",
       "      <td>0.608108</td>\n",
       "      <td>0.609196</td>\n",
       "      <td>0.608108</td>\n",
       "      <td>0.602412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1743</td>\n",
       "      <td>0.857200</td>\n",
       "      <td>0.876754</td>\n",
       "      <td>0.608473</td>\n",
       "      <td>0.608227</td>\n",
       "      <td>0.608473</td>\n",
       "      <td>0.597594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1764</td>\n",
       "      <td>0.781500</td>\n",
       "      <td>0.874250</td>\n",
       "      <td>0.605551</td>\n",
       "      <td>0.603350</td>\n",
       "      <td>0.605551</td>\n",
       "      <td>0.598639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1785</td>\n",
       "      <td>0.806800</td>\n",
       "      <td>0.881008</td>\n",
       "      <td>0.598247</td>\n",
       "      <td>0.600486</td>\n",
       "      <td>0.598247</td>\n",
       "      <td>0.598824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1806</td>\n",
       "      <td>0.861800</td>\n",
       "      <td>0.871975</td>\n",
       "      <td>0.606282</td>\n",
       "      <td>0.601693</td>\n",
       "      <td>0.606282</td>\n",
       "      <td>0.598698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1827</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.866959</td>\n",
       "      <td>0.609569</td>\n",
       "      <td>0.607423</td>\n",
       "      <td>0.609569</td>\n",
       "      <td>0.605859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1848</td>\n",
       "      <td>0.789900</td>\n",
       "      <td>0.866458</td>\n",
       "      <td>0.610299</td>\n",
       "      <td>0.606112</td>\n",
       "      <td>0.610299</td>\n",
       "      <td>0.606316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1869</td>\n",
       "      <td>0.788400</td>\n",
       "      <td>0.872372</td>\n",
       "      <td>0.602995</td>\n",
       "      <td>0.604721</td>\n",
       "      <td>0.602995</td>\n",
       "      <td>0.598776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>0.805900</td>\n",
       "      <td>0.865379</td>\n",
       "      <td>0.611030</td>\n",
       "      <td>0.606410</td>\n",
       "      <td>0.611030</td>\n",
       "      <td>0.604677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1911</td>\n",
       "      <td>0.854200</td>\n",
       "      <td>0.888663</td>\n",
       "      <td>0.600804</td>\n",
       "      <td>0.608364</td>\n",
       "      <td>0.600804</td>\n",
       "      <td>0.593542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1932</td>\n",
       "      <td>0.819200</td>\n",
       "      <td>0.873815</td>\n",
       "      <td>0.610665</td>\n",
       "      <td>0.610977</td>\n",
       "      <td>0.610665</td>\n",
       "      <td>0.598470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1953</td>\n",
       "      <td>0.836500</td>\n",
       "      <td>0.864248</td>\n",
       "      <td>0.612491</td>\n",
       "      <td>0.608671</td>\n",
       "      <td>0.612491</td>\n",
       "      <td>0.603064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1974</td>\n",
       "      <td>0.848800</td>\n",
       "      <td>0.863211</td>\n",
       "      <td>0.611760</td>\n",
       "      <td>0.607728</td>\n",
       "      <td>0.611760</td>\n",
       "      <td>0.607767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>0.855800</td>\n",
       "      <td>0.865433</td>\n",
       "      <td>0.608108</td>\n",
       "      <td>0.605313</td>\n",
       "      <td>0.608108</td>\n",
       "      <td>0.606054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016</td>\n",
       "      <td>0.784100</td>\n",
       "      <td>0.865441</td>\n",
       "      <td>0.608473</td>\n",
       "      <td>0.605676</td>\n",
       "      <td>0.608473</td>\n",
       "      <td>0.605952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2037</td>\n",
       "      <td>0.820500</td>\n",
       "      <td>0.863175</td>\n",
       "      <td>0.612856</td>\n",
       "      <td>0.608732</td>\n",
       "      <td>0.612856</td>\n",
       "      <td>0.608322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▂▃▄▃▃▄▄▅▅▆▅▅▅▆▆▇▆▇▆▆▆▇▇▇▇▇▇▇▇█▇▇███████</td></tr><tr><td>eval/f1</td><td>▂▂▂▂▃▁▄▄▅▅▆▆▅▅▆▅▇▇▇▇▇▅▇▇▇███▇▇██████████</td></tr><tr><td>eval/loss</td><td>█▇▇█▇▆▆▆▆▄▄▅▄▅▃▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▆▆▆▇▇▆▇▇▇▇▇▇▇█▇▇█▇██████████</td></tr><tr><td>eval/recall</td><td>▁▂▂▁▃▄▅▄▆▅▁▆▆▆▇▇▆▆▆▇▆▇▇▇▇▇▇▇████████████</td></tr><tr><td>eval/runtime</td><td>█▇▄▃▃▃▆▃█▃▃▃▆▃▃▃▄▃▁▁▂▄▂▄▁▅▄▅▃▂▁▂▂▃▂▃▁▂▂▄</td></tr><tr><td>eval/samples_per_second</td><td>▁▂▆▆▅▁▆▆▅▃▆▆▄▄▇▆██▄▇█▆▄▇▅▆█▂▇▆█▁▇▇▇▅▇█▇█</td></tr><tr><td>eval/steps_per_second</td><td>▂▆▆▆▃▁▆▂▆▅▃▃▃▆▄▇▆▇▅▇▇█▄█▆█▄█▆▇██▇▄███▇▇▂</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█</td></tr><tr><td>train/grad_norm</td><td>▄█▃▃▄▃▃▂▄▆▄▅▃▆▅▂▂▁▂█▆▁▃▂▃▂▃▄▂▂▁▂▁▂▂▄▄▅▂▁</td></tr><tr><td>train/learning_rate</td><td>▂▂▂▃▅▆▇▇████▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁</td></tr><tr><td>train/loss</td><td>█▇▇▇▆▆▅▆▅▆▅▅▅▄▄▃▅▅▄▄▃▄▄▃▂▂▄▂▂▂▁▁▁▂▁▂▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.61286</td></tr><tr><td>eval/f1</td><td>0.60832</td></tr><tr><td>eval/loss</td><td>0.86318</td></tr><tr><td>eval/precision</td><td>0.60873</td></tr><tr><td>eval/recall</td><td>0.61286</td></tr><tr><td>eval/runtime</td><td>2.5222</td></tr><tr><td>eval/samples_per_second</td><td>1085.567</td></tr><tr><td>eval/steps_per_second</td><td>68.195</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>2055</td></tr><tr><td>train/grad_norm</td><td>7.74007</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.8205</td></tr><tr><td>train_loss</td><td>0.94154</td></tr><tr><td>train_runtime</td><td>536.5736</td></tr><tr><td>train_samples_per_second</td><td>61.216</td></tr><tr><td>train_steps_per_second</td><td>3.83</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">urd-ipa</strong> at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/sx1hrrqj' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/sx1hrrqj</a><br> View project at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250805_120648-sx1hrrqj/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:47:57.531129790Z",
     "start_time": "2025-08-05T16:15:47.114583Z"
    }
   },
   "cell_type": "code",
   "source": "finetune_transcription('urd', 'urd', True, model)",
   "id": "db887d645e5412a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuning on urd ipa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/workspace/github/IPA_Finetuning/wandb/run-20250805_121547-rn7x3dak</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/rn7x3dak' target=\"_blank\">urd-urd-ipa</a></strong> to <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/rn7x3dak' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/rn7x3dak</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation on urd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='172' max='172' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [172/172 00:02]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8738154768943787, 'eval_accuracy': 0.6106647187728269, 'eval_precision': 0.6109767155664939, 'eval_recall': 0.6106647187728269, 'eval_f1': 0.5984703363788032, 'eval_runtime': 2.6108, 'eval_samples_per_second': 1048.73, 'eval_steps_per_second': 65.881, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.61066</td></tr><tr><td>eval/f1</td><td>0.59847</td></tr><tr><td>eval/loss</td><td>0.87382</td></tr><tr><td>eval/precision</td><td>0.61098</td></tr><tr><td>eval/recall</td><td>0.61066</td></tr><tr><td>eval/runtime</td><td>2.6108</td></tr><tr><td>eval/samples_per_second</td><td>1048.73</td></tr><tr><td>eval/steps_per_second</td><td>65.881</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>2055</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">urd-urd-ipa</strong> at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/rn7x3dak' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/rn7x3dak</a><br> View project at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250805_121547-rn7x3dak/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:47:57.531403634Z",
     "start_time": "2025-08-05T16:15:52.200475Z"
    }
   },
   "cell_type": "code",
   "source": "model = train_model('both', False)",
   "id": "59fa5c256ed8679",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 123.35M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/workspace/github/IPA_Finetuning/wandb/run-20250805_121556-zio04fb2</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/zio04fb2' target=\"_blank\">both-normal</a></strong> to <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/zio04fb2' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/zio04fb2</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_949323/2041274532.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2190' max='2190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2190/2190 13:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.169000</td>\n",
       "      <td>1.119362</td>\n",
       "      <td>0.412269</td>\n",
       "      <td>0.405745</td>\n",
       "      <td>0.412269</td>\n",
       "      <td>0.406917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.099200</td>\n",
       "      <td>1.066482</td>\n",
       "      <td>0.427005</td>\n",
       "      <td>0.408457</td>\n",
       "      <td>0.427005</td>\n",
       "      <td>0.412610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.057200</td>\n",
       "      <td>1.021486</td>\n",
       "      <td>0.449623</td>\n",
       "      <td>0.424308</td>\n",
       "      <td>0.449623</td>\n",
       "      <td>0.422563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.008300</td>\n",
       "      <td>0.996762</td>\n",
       "      <td>0.469157</td>\n",
       "      <td>0.449060</td>\n",
       "      <td>0.469157</td>\n",
       "      <td>0.444644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.011400</td>\n",
       "      <td>0.982128</td>\n",
       "      <td>0.476696</td>\n",
       "      <td>0.470299</td>\n",
       "      <td>0.476696</td>\n",
       "      <td>0.460171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>1.002400</td>\n",
       "      <td>0.973767</td>\n",
       "      <td>0.477382</td>\n",
       "      <td>0.481078</td>\n",
       "      <td>0.477382</td>\n",
       "      <td>0.475393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>1.021200</td>\n",
       "      <td>0.956164</td>\n",
       "      <td>0.502742</td>\n",
       "      <td>0.484360</td>\n",
       "      <td>0.502742</td>\n",
       "      <td>0.476162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>0.945102</td>\n",
       "      <td>0.506511</td>\n",
       "      <td>0.502047</td>\n",
       "      <td>0.506511</td>\n",
       "      <td>0.502893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.984200</td>\n",
       "      <td>0.953856</td>\n",
       "      <td>0.508910</td>\n",
       "      <td>0.505217</td>\n",
       "      <td>0.508910</td>\n",
       "      <td>0.497495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.004100</td>\n",
       "      <td>0.953585</td>\n",
       "      <td>0.503770</td>\n",
       "      <td>0.530816</td>\n",
       "      <td>0.503770</td>\n",
       "      <td>0.477450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>0.977500</td>\n",
       "      <td>0.958956</td>\n",
       "      <td>0.484921</td>\n",
       "      <td>0.508065</td>\n",
       "      <td>0.484921</td>\n",
       "      <td>0.492368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>0.976300</td>\n",
       "      <td>0.944763</td>\n",
       "      <td>0.510281</td>\n",
       "      <td>0.488579</td>\n",
       "      <td>0.510281</td>\n",
       "      <td>0.478772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>0.966600</td>\n",
       "      <td>0.954143</td>\n",
       "      <td>0.504798</td>\n",
       "      <td>0.498969</td>\n",
       "      <td>0.504798</td>\n",
       "      <td>0.484185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>308</td>\n",
       "      <td>0.955500</td>\n",
       "      <td>0.952713</td>\n",
       "      <td>0.495545</td>\n",
       "      <td>0.536547</td>\n",
       "      <td>0.495545</td>\n",
       "      <td>0.503854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>0.947617</td>\n",
       "      <td>0.504798</td>\n",
       "      <td>0.509529</td>\n",
       "      <td>0.504798</td>\n",
       "      <td>0.505181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>1.026600</td>\n",
       "      <td>0.988085</td>\n",
       "      <td>0.504112</td>\n",
       "      <td>0.547610</td>\n",
       "      <td>0.504112</td>\n",
       "      <td>0.463361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.934814</td>\n",
       "      <td>0.516450</td>\n",
       "      <td>0.497918</td>\n",
       "      <td>0.516450</td>\n",
       "      <td>0.499898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>0.904600</td>\n",
       "      <td>0.940277</td>\n",
       "      <td>0.522961</td>\n",
       "      <td>0.521168</td>\n",
       "      <td>0.522961</td>\n",
       "      <td>0.520499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>418</td>\n",
       "      <td>0.957600</td>\n",
       "      <td>0.960573</td>\n",
       "      <td>0.525360</td>\n",
       "      <td>0.534550</td>\n",
       "      <td>0.525360</td>\n",
       "      <td>0.519621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.933975</td>\n",
       "      <td>0.532899</td>\n",
       "      <td>0.510401</td>\n",
       "      <td>0.532899</td>\n",
       "      <td>0.495519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462</td>\n",
       "      <td>0.955900</td>\n",
       "      <td>0.935512</td>\n",
       "      <td>0.547635</td>\n",
       "      <td>0.531753</td>\n",
       "      <td>0.547635</td>\n",
       "      <td>0.531333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484</td>\n",
       "      <td>1.021500</td>\n",
       "      <td>0.933026</td>\n",
       "      <td>0.538040</td>\n",
       "      <td>0.562157</td>\n",
       "      <td>0.538040</td>\n",
       "      <td>0.539615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>506</td>\n",
       "      <td>0.913300</td>\n",
       "      <td>0.927696</td>\n",
       "      <td>0.536669</td>\n",
       "      <td>0.542187</td>\n",
       "      <td>0.536669</td>\n",
       "      <td>0.527196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>528</td>\n",
       "      <td>1.006300</td>\n",
       "      <td>0.964536</td>\n",
       "      <td>0.527759</td>\n",
       "      <td>0.553882</td>\n",
       "      <td>0.527759</td>\n",
       "      <td>0.517621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.005500</td>\n",
       "      <td>0.932253</td>\n",
       "      <td>0.518849</td>\n",
       "      <td>0.517345</td>\n",
       "      <td>0.518849</td>\n",
       "      <td>0.508080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>572</td>\n",
       "      <td>0.943100</td>\n",
       "      <td>0.911127</td>\n",
       "      <td>0.542152</td>\n",
       "      <td>0.544034</td>\n",
       "      <td>0.542152</td>\n",
       "      <td>0.542754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>594</td>\n",
       "      <td>1.016800</td>\n",
       "      <td>0.956681</td>\n",
       "      <td>0.522618</td>\n",
       "      <td>0.548231</td>\n",
       "      <td>0.522618</td>\n",
       "      <td>0.522206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>616</td>\n",
       "      <td>0.950600</td>\n",
       "      <td>0.966670</td>\n",
       "      <td>0.521590</td>\n",
       "      <td>0.546230</td>\n",
       "      <td>0.521590</td>\n",
       "      <td>0.496921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>638</td>\n",
       "      <td>0.945400</td>\n",
       "      <td>0.912816</td>\n",
       "      <td>0.542838</td>\n",
       "      <td>0.530996</td>\n",
       "      <td>0.542838</td>\n",
       "      <td>0.527901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.994900</td>\n",
       "      <td>0.934268</td>\n",
       "      <td>0.543180</td>\n",
       "      <td>0.547770</td>\n",
       "      <td>0.543180</td>\n",
       "      <td>0.534984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>682</td>\n",
       "      <td>0.983500</td>\n",
       "      <td>0.966945</td>\n",
       "      <td>0.488005</td>\n",
       "      <td>0.530941</td>\n",
       "      <td>0.488005</td>\n",
       "      <td>0.483310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>704</td>\n",
       "      <td>0.986700</td>\n",
       "      <td>0.906398</td>\n",
       "      <td>0.551405</td>\n",
       "      <td>0.539036</td>\n",
       "      <td>0.551405</td>\n",
       "      <td>0.536439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>726</td>\n",
       "      <td>0.981300</td>\n",
       "      <td>0.921033</td>\n",
       "      <td>0.543523</td>\n",
       "      <td>0.543256</td>\n",
       "      <td>0.543523</td>\n",
       "      <td>0.534214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>748</td>\n",
       "      <td>0.934000</td>\n",
       "      <td>0.896641</td>\n",
       "      <td>0.545236</td>\n",
       "      <td>0.547813</td>\n",
       "      <td>0.545236</td>\n",
       "      <td>0.546258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.841100</td>\n",
       "      <td>0.908558</td>\n",
       "      <td>0.553804</td>\n",
       "      <td>0.548311</td>\n",
       "      <td>0.553804</td>\n",
       "      <td>0.547196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>792</td>\n",
       "      <td>0.886100</td>\n",
       "      <td>0.917800</td>\n",
       "      <td>0.550377</td>\n",
       "      <td>0.544963</td>\n",
       "      <td>0.550377</td>\n",
       "      <td>0.545828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>814</td>\n",
       "      <td>0.916700</td>\n",
       "      <td>0.887291</td>\n",
       "      <td>0.562714</td>\n",
       "      <td>0.561616</td>\n",
       "      <td>0.562714</td>\n",
       "      <td>0.557449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>836</td>\n",
       "      <td>0.843700</td>\n",
       "      <td>0.912573</td>\n",
       "      <td>0.547293</td>\n",
       "      <td>0.538416</td>\n",
       "      <td>0.547293</td>\n",
       "      <td>0.530943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>858</td>\n",
       "      <td>0.937200</td>\n",
       "      <td>0.940188</td>\n",
       "      <td>0.525360</td>\n",
       "      <td>0.589410</td>\n",
       "      <td>0.525360</td>\n",
       "      <td>0.530941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.875300</td>\n",
       "      <td>0.912221</td>\n",
       "      <td>0.560315</td>\n",
       "      <td>0.557206</td>\n",
       "      <td>0.560315</td>\n",
       "      <td>0.556260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>902</td>\n",
       "      <td>0.873400</td>\n",
       "      <td>0.904392</td>\n",
       "      <td>0.550720</td>\n",
       "      <td>0.579008</td>\n",
       "      <td>0.550720</td>\n",
       "      <td>0.553760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>924</td>\n",
       "      <td>0.928700</td>\n",
       "      <td>0.941365</td>\n",
       "      <td>0.542495</td>\n",
       "      <td>0.548942</td>\n",
       "      <td>0.542495</td>\n",
       "      <td>0.498041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>946</td>\n",
       "      <td>0.897200</td>\n",
       "      <td>0.920491</td>\n",
       "      <td>0.543180</td>\n",
       "      <td>0.605758</td>\n",
       "      <td>0.543180</td>\n",
       "      <td>0.544512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>968</td>\n",
       "      <td>0.876100</td>\n",
       "      <td>0.887113</td>\n",
       "      <td>0.576422</td>\n",
       "      <td>0.571951</td>\n",
       "      <td>0.576422</td>\n",
       "      <td>0.560646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.907100</td>\n",
       "      <td>0.908251</td>\n",
       "      <td>0.566827</td>\n",
       "      <td>0.580510</td>\n",
       "      <td>0.566827</td>\n",
       "      <td>0.561039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1012</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.921838</td>\n",
       "      <td>0.527073</td>\n",
       "      <td>0.610199</td>\n",
       "      <td>0.527073</td>\n",
       "      <td>0.534030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1034</td>\n",
       "      <td>0.886500</td>\n",
       "      <td>0.876717</td>\n",
       "      <td>0.569911</td>\n",
       "      <td>0.571460</td>\n",
       "      <td>0.569911</td>\n",
       "      <td>0.560651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1056</td>\n",
       "      <td>0.854900</td>\n",
       "      <td>0.887439</td>\n",
       "      <td>0.559287</td>\n",
       "      <td>0.558502</td>\n",
       "      <td>0.559287</td>\n",
       "      <td>0.555813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1078</td>\n",
       "      <td>0.957200</td>\n",
       "      <td>0.899812</td>\n",
       "      <td>0.549349</td>\n",
       "      <td>0.581964</td>\n",
       "      <td>0.549349</td>\n",
       "      <td>0.543468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.891500</td>\n",
       "      <td>0.890401</td>\n",
       "      <td>0.557574</td>\n",
       "      <td>0.578141</td>\n",
       "      <td>0.557574</td>\n",
       "      <td>0.556132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1122</td>\n",
       "      <td>0.905400</td>\n",
       "      <td>0.876300</td>\n",
       "      <td>0.570596</td>\n",
       "      <td>0.565521</td>\n",
       "      <td>0.570596</td>\n",
       "      <td>0.547376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1144</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.896122</td>\n",
       "      <td>0.563742</td>\n",
       "      <td>0.588298</td>\n",
       "      <td>0.563742</td>\n",
       "      <td>0.555047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1166</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.859430</td>\n",
       "      <td>0.586018</td>\n",
       "      <td>0.579521</td>\n",
       "      <td>0.586018</td>\n",
       "      <td>0.576644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1188</td>\n",
       "      <td>0.898800</td>\n",
       "      <td>0.900094</td>\n",
       "      <td>0.569911</td>\n",
       "      <td>0.609156</td>\n",
       "      <td>0.569911</td>\n",
       "      <td>0.560593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.880600</td>\n",
       "      <td>0.857945</td>\n",
       "      <td>0.587731</td>\n",
       "      <td>0.593973</td>\n",
       "      <td>0.587731</td>\n",
       "      <td>0.586643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1232</td>\n",
       "      <td>0.913000</td>\n",
       "      <td>0.862522</td>\n",
       "      <td>0.586361</td>\n",
       "      <td>0.583752</td>\n",
       "      <td>0.586361</td>\n",
       "      <td>0.570021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1254</td>\n",
       "      <td>0.803000</td>\n",
       "      <td>0.898098</td>\n",
       "      <td>0.574366</td>\n",
       "      <td>0.601012</td>\n",
       "      <td>0.574366</td>\n",
       "      <td>0.558490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1276</td>\n",
       "      <td>0.884100</td>\n",
       "      <td>0.875547</td>\n",
       "      <td>0.569225</td>\n",
       "      <td>0.596706</td>\n",
       "      <td>0.569225</td>\n",
       "      <td>0.568507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1298</td>\n",
       "      <td>0.824300</td>\n",
       "      <td>0.852575</td>\n",
       "      <td>0.583962</td>\n",
       "      <td>0.591415</td>\n",
       "      <td>0.583962</td>\n",
       "      <td>0.586583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.903500</td>\n",
       "      <td>0.858969</td>\n",
       "      <td>0.581563</td>\n",
       "      <td>0.588473</td>\n",
       "      <td>0.581563</td>\n",
       "      <td>0.584036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1342</td>\n",
       "      <td>0.840800</td>\n",
       "      <td>0.874048</td>\n",
       "      <td>0.573681</td>\n",
       "      <td>0.615572</td>\n",
       "      <td>0.573681</td>\n",
       "      <td>0.581024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1364</td>\n",
       "      <td>0.888600</td>\n",
       "      <td>0.876238</td>\n",
       "      <td>0.574366</td>\n",
       "      <td>0.586699</td>\n",
       "      <td>0.574366</td>\n",
       "      <td>0.563503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1386</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.873919</td>\n",
       "      <td>0.571967</td>\n",
       "      <td>0.612455</td>\n",
       "      <td>0.571967</td>\n",
       "      <td>0.572571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1408</td>\n",
       "      <td>0.804100</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.591158</td>\n",
       "      <td>0.589560</td>\n",
       "      <td>0.591158</td>\n",
       "      <td>0.590256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>0.827500</td>\n",
       "      <td>0.852597</td>\n",
       "      <td>0.591158</td>\n",
       "      <td>0.592144</td>\n",
       "      <td>0.591158</td>\n",
       "      <td>0.589580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1452</td>\n",
       "      <td>0.880900</td>\n",
       "      <td>0.852158</td>\n",
       "      <td>0.588759</td>\n",
       "      <td>0.585573</td>\n",
       "      <td>0.588759</td>\n",
       "      <td>0.585578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1474</td>\n",
       "      <td>0.855100</td>\n",
       "      <td>0.852349</td>\n",
       "      <td>0.581905</td>\n",
       "      <td>0.605990</td>\n",
       "      <td>0.581905</td>\n",
       "      <td>0.586604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1496</td>\n",
       "      <td>0.820600</td>\n",
       "      <td>0.854258</td>\n",
       "      <td>0.591844</td>\n",
       "      <td>0.595069</td>\n",
       "      <td>0.591844</td>\n",
       "      <td>0.590903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1518</td>\n",
       "      <td>0.770200</td>\n",
       "      <td>0.860311</td>\n",
       "      <td>0.594585</td>\n",
       "      <td>0.589160</td>\n",
       "      <td>0.594585</td>\n",
       "      <td>0.587816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.856800</td>\n",
       "      <td>0.870405</td>\n",
       "      <td>0.590473</td>\n",
       "      <td>0.606275</td>\n",
       "      <td>0.590473</td>\n",
       "      <td>0.591678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1562</td>\n",
       "      <td>0.847700</td>\n",
       "      <td>0.869476</td>\n",
       "      <td>0.588759</td>\n",
       "      <td>0.601876</td>\n",
       "      <td>0.588759</td>\n",
       "      <td>0.586188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1584</td>\n",
       "      <td>0.803400</td>\n",
       "      <td>0.854319</td>\n",
       "      <td>0.593900</td>\n",
       "      <td>0.599069</td>\n",
       "      <td>0.593900</td>\n",
       "      <td>0.595626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1606</td>\n",
       "      <td>0.801900</td>\n",
       "      <td>0.845017</td>\n",
       "      <td>0.607608</td>\n",
       "      <td>0.604715</td>\n",
       "      <td>0.607608</td>\n",
       "      <td>0.604107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1628</td>\n",
       "      <td>0.805600</td>\n",
       "      <td>0.848164</td>\n",
       "      <td>0.599726</td>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.599726</td>\n",
       "      <td>0.600458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.806500</td>\n",
       "      <td>0.847286</td>\n",
       "      <td>0.607951</td>\n",
       "      <td>0.607790</td>\n",
       "      <td>0.607951</td>\n",
       "      <td>0.604385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1672</td>\n",
       "      <td>0.846200</td>\n",
       "      <td>0.860721</td>\n",
       "      <td>0.596642</td>\n",
       "      <td>0.612163</td>\n",
       "      <td>0.596642</td>\n",
       "      <td>0.600136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1694</td>\n",
       "      <td>0.787700</td>\n",
       "      <td>0.842023</td>\n",
       "      <td>0.609664</td>\n",
       "      <td>0.613858</td>\n",
       "      <td>0.609664</td>\n",
       "      <td>0.611318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1716</td>\n",
       "      <td>0.807200</td>\n",
       "      <td>0.849504</td>\n",
       "      <td>0.606923</td>\n",
       "      <td>0.613128</td>\n",
       "      <td>0.606923</td>\n",
       "      <td>0.605192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1738</td>\n",
       "      <td>0.737900</td>\n",
       "      <td>0.843578</td>\n",
       "      <td>0.597670</td>\n",
       "      <td>0.595632</td>\n",
       "      <td>0.597670</td>\n",
       "      <td>0.596104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.758700</td>\n",
       "      <td>0.840143</td>\n",
       "      <td>0.605209</td>\n",
       "      <td>0.600487</td>\n",
       "      <td>0.605209</td>\n",
       "      <td>0.597138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1782</td>\n",
       "      <td>0.743300</td>\n",
       "      <td>0.845210</td>\n",
       "      <td>0.606237</td>\n",
       "      <td>0.622060</td>\n",
       "      <td>0.606237</td>\n",
       "      <td>0.610015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1804</td>\n",
       "      <td>0.780800</td>\n",
       "      <td>0.858048</td>\n",
       "      <td>0.606923</td>\n",
       "      <td>0.617946</td>\n",
       "      <td>0.606923</td>\n",
       "      <td>0.597418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1826</td>\n",
       "      <td>0.832500</td>\n",
       "      <td>0.843911</td>\n",
       "      <td>0.600754</td>\n",
       "      <td>0.614340</td>\n",
       "      <td>0.600754</td>\n",
       "      <td>0.603705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1848</td>\n",
       "      <td>0.741900</td>\n",
       "      <td>0.841073</td>\n",
       "      <td>0.606580</td>\n",
       "      <td>0.610446</td>\n",
       "      <td>0.606580</td>\n",
       "      <td>0.606595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1870</td>\n",
       "      <td>0.779800</td>\n",
       "      <td>0.837646</td>\n",
       "      <td>0.603838</td>\n",
       "      <td>0.605735</td>\n",
       "      <td>0.603838</td>\n",
       "      <td>0.596928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1892</td>\n",
       "      <td>0.753800</td>\n",
       "      <td>0.835067</td>\n",
       "      <td>0.613777</td>\n",
       "      <td>0.619203</td>\n",
       "      <td>0.613777</td>\n",
       "      <td>0.614775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1914</td>\n",
       "      <td>0.809100</td>\n",
       "      <td>0.833371</td>\n",
       "      <td>0.610692</td>\n",
       "      <td>0.614078</td>\n",
       "      <td>0.610692</td>\n",
       "      <td>0.609428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1936</td>\n",
       "      <td>0.747000</td>\n",
       "      <td>0.838556</td>\n",
       "      <td>0.613777</td>\n",
       "      <td>0.619074</td>\n",
       "      <td>0.613777</td>\n",
       "      <td>0.611058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1958</td>\n",
       "      <td>0.783100</td>\n",
       "      <td>0.830119</td>\n",
       "      <td>0.614119</td>\n",
       "      <td>0.612505</td>\n",
       "      <td>0.614119</td>\n",
       "      <td>0.610258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.790200</td>\n",
       "      <td>0.830398</td>\n",
       "      <td>0.616175</td>\n",
       "      <td>0.613272</td>\n",
       "      <td>0.616175</td>\n",
       "      <td>0.613772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2002</td>\n",
       "      <td>0.746700</td>\n",
       "      <td>0.837138</td>\n",
       "      <td>0.613434</td>\n",
       "      <td>0.624860</td>\n",
       "      <td>0.613434</td>\n",
       "      <td>0.615988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2024</td>\n",
       "      <td>0.761600</td>\n",
       "      <td>0.829880</td>\n",
       "      <td>0.617546</td>\n",
       "      <td>0.613848</td>\n",
       "      <td>0.617546</td>\n",
       "      <td>0.613075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2046</td>\n",
       "      <td>0.732500</td>\n",
       "      <td>0.829120</td>\n",
       "      <td>0.614462</td>\n",
       "      <td>0.609791</td>\n",
       "      <td>0.614462</td>\n",
       "      <td>0.608525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2068</td>\n",
       "      <td>0.774600</td>\n",
       "      <td>0.827191</td>\n",
       "      <td>0.614462</td>\n",
       "      <td>0.611634</td>\n",
       "      <td>0.614462</td>\n",
       "      <td>0.611003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2090</td>\n",
       "      <td>0.818000</td>\n",
       "      <td>0.827819</td>\n",
       "      <td>0.616518</td>\n",
       "      <td>0.618770</td>\n",
       "      <td>0.616518</td>\n",
       "      <td>0.615230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2112</td>\n",
       "      <td>0.748200</td>\n",
       "      <td>0.824722</td>\n",
       "      <td>0.616861</td>\n",
       "      <td>0.617014</td>\n",
       "      <td>0.616861</td>\n",
       "      <td>0.616325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2134</td>\n",
       "      <td>0.772500</td>\n",
       "      <td>0.824207</td>\n",
       "      <td>0.618574</td>\n",
       "      <td>0.618380</td>\n",
       "      <td>0.618574</td>\n",
       "      <td>0.617680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2156</td>\n",
       "      <td>0.766500</td>\n",
       "      <td>0.823517</td>\n",
       "      <td>0.615147</td>\n",
       "      <td>0.612000</td>\n",
       "      <td>0.615147</td>\n",
       "      <td>0.612350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2178</td>\n",
       "      <td>0.711800</td>\n",
       "      <td>0.823467</td>\n",
       "      <td>0.617204</td>\n",
       "      <td>0.613452</td>\n",
       "      <td>0.617204</td>\n",
       "      <td>0.613857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▂▃▃▄▄▄▄▅▆▅▅▅▅▅▆▅▆▆▅▆▆▇▆▇▆▇▇▇▇▇█████████</td></tr><tr><td>eval/f1</td><td>▁▂▂▃▂▃▂▄▄▄▄▃▅▆▆▆▆▆▅▆▇▆▆▇▇▇▇▇▇▇█▇▇███████</td></tr><tr><td>eval/loss</td><td>█▇▅▅▅▆▄▄▄▄▄▅▄▃▄▄▄▄▃▄▃▃▂▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▂▃▅▄▅▄▅▄▅▅▄▅▅▅▅▅▆▇█▇▇▇▇█▇█▇▇█▇█████████</td></tr><tr><td>eval/recall</td><td>▂▂▂▁▂▃▃▃▄▃▄▄▁▄▄▃▅▄▅▃▄▅▆▅▆▅▆▆▇▇▇▆▇█▇▇████</td></tr><tr><td>eval/runtime</td><td>▆▃▄▅▆▂▅▄▂▂█▂▂▅▅▄▁▂▂▂▁▃▄▁▃▂▄▇▂▂▅▄▅▂▃▅▂▆▂▃</td></tr><tr><td>eval/samples_per_second</td><td>▆▇█▇▅▂▇▁▇▇▅▇▇▇▇▅▁▆▆▆▄▇▇▆▆▇▇▄▅█▇▅▂▇▇▅▆▄▄▆</td></tr><tr><td>eval/steps_per_second</td><td>▆█▇▅▅▇▇▇▇▇▇▁▆▆▄▅▇▆▇▇▅▇▄▄█▇█▇▇▅▇▇▇▇▆▇▄▃▃▆</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▆▆▅▅▆▄▄▆▄▄▄▄▅▂█▆▄█▆▆▃▅█▄▁▂▃▂▄▄▅▃▂▃▇▂▄▃▃▅</td></tr><tr><td>train/learning_rate</td><td>▁▂▂▂▃▄▅▅▅▆▆▇███▇▇▇▇▇▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▅▅▅▅▅▅▅▆▆▅▅▅▅▅▃▄▃▅▄▄▄▂▄▄▄▃▃▂▂▂▁▂▂▂▂▁▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.6172</td></tr><tr><td>eval/f1</td><td>0.61386</td></tr><tr><td>eval/loss</td><td>0.82347</td></tr><tr><td>eval/precision</td><td>0.61345</td></tr><tr><td>eval/recall</td><td>0.6172</td></tr><tr><td>eval/runtime</td><td>2.7631</td></tr><tr><td>eval/samples_per_second</td><td>1056.071</td></tr><tr><td>eval/steps_per_second</td><td>66.231</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>2190</td></tr><tr><td>train/grad_norm</td><td>7.07559</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7118</td></tr><tr><td>train_loss</td><td>0.88512</td></tr><tr><td>train_runtime</td><td>821.4835</td></tr><tr><td>train_samples_per_second</td><td>42.607</td></tr><tr><td>train_steps_per_second</td><td>2.666</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">both-normal</strong> at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/zio04fb2' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/zio04fb2</a><br> View project at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250805_121556-zio04fb2/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:47:57.532429008Z",
     "start_time": "2025-08-05T16:29:40.459816Z"
    }
   },
   "cell_type": "code",
   "source": "finetune_transcription('both', 'hin', False, model)",
   "id": "d12a065138768c21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuning on hin normal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/workspace/github/IPA_Finetuning/wandb/run-20250805_122941-stbg9sy5</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/stbg9sy5' target=\"_blank\">both-hin-normal</a></strong> to <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/stbg9sy5' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/stbg9sy5</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation on hin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1249783039093018, 'eval_accuracy': 0.39444444444444443, 'eval_precision': 0.36400384227765176, 'eval_recall': 0.39444444444444443, 'eval_f1': 0.33342777777777777, 'eval_runtime': 0.9833, 'eval_samples_per_second': 183.056, 'eval_steps_per_second': 12.204, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.39444</td></tr><tr><td>eval/f1</td><td>0.33343</td></tr><tr><td>eval/loss</td><td>1.12498</td></tr><tr><td>eval/precision</td><td>0.364</td></tr><tr><td>eval/recall</td><td>0.39444</td></tr><tr><td>eval/runtime</td><td>0.9833</td></tr><tr><td>eval/samples_per_second</td><td>183.056</td></tr><tr><td>eval/steps_per_second</td><td>12.204</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>2190</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">both-hin-normal</strong> at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/stbg9sy5' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/stbg9sy5</a><br> View project at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='184' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:04]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:47:57.532734812Z",
     "start_time": "2025-08-05T16:29:43.997074Z"
    }
   },
   "cell_type": "code",
   "source": "finetune_transcription('both', 'urd', False, model)",
   "id": "e558b1fe2eb00214",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuning on urd normal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/workspace/github/IPA_Finetuning/wandb/run-20250805_122944-8avn6im5</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/8avn6im5' target=\"_blank\">both-urd-normal</a></strong> to <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/8avn6im5' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/8avn6im5</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation on urd\n",
      "{'eval_loss': 0.8182193636894226, 'eval_accuracy': 0.6278305332359386, 'eval_precision': 0.6360188870198712, 'eval_recall': 0.6278305332359386, 'eval_f1': 0.6300529666597294, 'eval_runtime': 1.9257, 'eval_samples_per_second': 1421.846, 'eval_steps_per_second': 89.32, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.62783</td></tr><tr><td>eval/f1</td><td>0.63005</td></tr><tr><td>eval/loss</td><td>0.81822</td></tr><tr><td>eval/precision</td><td>0.63602</td></tr><tr><td>eval/recall</td><td>0.62783</td></tr><tr><td>eval/runtime</td><td>1.9257</td></tr><tr><td>eval/samples_per_second</td><td>1421.846</td></tr><tr><td>eval/steps_per_second</td><td>89.32</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>2190</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">both-urd-normal</strong> at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/8avn6im5' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/8avn6im5</a><br> View project at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250805_122944-8avn6im5/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:47:57.532954625Z",
     "start_time": "2025-08-05T16:29:47.942244Z"
    }
   },
   "cell_type": "code",
   "source": "model = train_model('both', True)",
   "id": "a39964a47debb051",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 123.35M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/workspace/github/IPA_Finetuning/wandb/run-20250805_122951-3re1tt5k</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/3re1tt5k' target=\"_blank\">both-ipa</a></strong> to <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/3re1tt5k' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/3re1tt5k</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_949323/2041274532.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2190' max='2190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2190/2190 14:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.184100</td>\n",
       "      <td>1.153490</td>\n",
       "      <td>0.338245</td>\n",
       "      <td>0.374076</td>\n",
       "      <td>0.338245</td>\n",
       "      <td>0.340743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.160200</td>\n",
       "      <td>1.104608</td>\n",
       "      <td>0.402673</td>\n",
       "      <td>0.367311</td>\n",
       "      <td>0.402673</td>\n",
       "      <td>0.360764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.114200</td>\n",
       "      <td>1.098252</td>\n",
       "      <td>0.429061</td>\n",
       "      <td>0.376201</td>\n",
       "      <td>0.429061</td>\n",
       "      <td>0.348084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.111000</td>\n",
       "      <td>1.106913</td>\n",
       "      <td>0.395819</td>\n",
       "      <td>0.390010</td>\n",
       "      <td>0.395819</td>\n",
       "      <td>0.359434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.096700</td>\n",
       "      <td>1.082427</td>\n",
       "      <td>0.421179</td>\n",
       "      <td>0.378773</td>\n",
       "      <td>0.421179</td>\n",
       "      <td>0.369560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>1.143600</td>\n",
       "      <td>1.074089</td>\n",
       "      <td>0.434887</td>\n",
       "      <td>0.389975</td>\n",
       "      <td>0.434887</td>\n",
       "      <td>0.364891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>1.101800</td>\n",
       "      <td>1.066502</td>\n",
       "      <td>0.433859</td>\n",
       "      <td>0.399181</td>\n",
       "      <td>0.433859</td>\n",
       "      <td>0.385221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>1.108100</td>\n",
       "      <td>1.072123</td>\n",
       "      <td>0.444140</td>\n",
       "      <td>0.407529</td>\n",
       "      <td>0.444140</td>\n",
       "      <td>0.376222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>1.100300</td>\n",
       "      <td>1.063484</td>\n",
       "      <td>0.436943</td>\n",
       "      <td>0.424928</td>\n",
       "      <td>0.436943</td>\n",
       "      <td>0.417459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.079500</td>\n",
       "      <td>1.073272</td>\n",
       "      <td>0.442426</td>\n",
       "      <td>0.445634</td>\n",
       "      <td>0.442426</td>\n",
       "      <td>0.391857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>1.105400</td>\n",
       "      <td>1.065309</td>\n",
       "      <td>0.442426</td>\n",
       "      <td>0.421352</td>\n",
       "      <td>0.442426</td>\n",
       "      <td>0.398322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>1.086800</td>\n",
       "      <td>1.047102</td>\n",
       "      <td>0.466073</td>\n",
       "      <td>0.446686</td>\n",
       "      <td>0.466073</td>\n",
       "      <td>0.382282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>1.046800</td>\n",
       "      <td>1.068763</td>\n",
       "      <td>0.435572</td>\n",
       "      <td>0.443843</td>\n",
       "      <td>0.435572</td>\n",
       "      <td>0.414143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>308</td>\n",
       "      <td>1.105600</td>\n",
       "      <td>1.045034</td>\n",
       "      <td>0.456477</td>\n",
       "      <td>0.454823</td>\n",
       "      <td>0.456477</td>\n",
       "      <td>0.444270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.074800</td>\n",
       "      <td>1.041365</td>\n",
       "      <td>0.469500</td>\n",
       "      <td>0.460357</td>\n",
       "      <td>0.469500</td>\n",
       "      <td>0.448779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>1.024800</td>\n",
       "      <td>1.073575</td>\n",
       "      <td>0.468472</td>\n",
       "      <td>0.442166</td>\n",
       "      <td>0.468472</td>\n",
       "      <td>0.409894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>1.053600</td>\n",
       "      <td>1.061320</td>\n",
       "      <td>0.462646</td>\n",
       "      <td>0.445657</td>\n",
       "      <td>0.462646</td>\n",
       "      <td>0.420438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>1.033700</td>\n",
       "      <td>1.006856</td>\n",
       "      <td>0.489034</td>\n",
       "      <td>0.473538</td>\n",
       "      <td>0.489034</td>\n",
       "      <td>0.476639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>418</td>\n",
       "      <td>1.081300</td>\n",
       "      <td>1.004914</td>\n",
       "      <td>0.497601</td>\n",
       "      <td>0.482538</td>\n",
       "      <td>0.497601</td>\n",
       "      <td>0.476114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.021700</td>\n",
       "      <td>1.033813</td>\n",
       "      <td>0.491432</td>\n",
       "      <td>0.501145</td>\n",
       "      <td>0.491432</td>\n",
       "      <td>0.408815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462</td>\n",
       "      <td>0.991700</td>\n",
       "      <td>1.039730</td>\n",
       "      <td>0.499315</td>\n",
       "      <td>0.494654</td>\n",
       "      <td>0.499315</td>\n",
       "      <td>0.444077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484</td>\n",
       "      <td>1.051100</td>\n",
       "      <td>1.034062</td>\n",
       "      <td>0.487320</td>\n",
       "      <td>0.511886</td>\n",
       "      <td>0.487320</td>\n",
       "      <td>0.486431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>506</td>\n",
       "      <td>1.028200</td>\n",
       "      <td>1.020107</td>\n",
       "      <td>0.488348</td>\n",
       "      <td>0.479009</td>\n",
       "      <td>0.488348</td>\n",
       "      <td>0.449252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>528</td>\n",
       "      <td>1.039800</td>\n",
       "      <td>1.068842</td>\n",
       "      <td>0.461960</td>\n",
       "      <td>0.517592</td>\n",
       "      <td>0.461960</td>\n",
       "      <td>0.417047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.025200</td>\n",
       "      <td>0.980459</td>\n",
       "      <td>0.517478</td>\n",
       "      <td>0.500827</td>\n",
       "      <td>0.517478</td>\n",
       "      <td>0.465536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>572</td>\n",
       "      <td>1.032900</td>\n",
       "      <td>1.000485</td>\n",
       "      <td>0.489719</td>\n",
       "      <td>0.497470</td>\n",
       "      <td>0.489719</td>\n",
       "      <td>0.467531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>594</td>\n",
       "      <td>1.015400</td>\n",
       "      <td>0.980751</td>\n",
       "      <td>0.523646</td>\n",
       "      <td>0.523860</td>\n",
       "      <td>0.523646</td>\n",
       "      <td>0.483645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>616</td>\n",
       "      <td>0.959900</td>\n",
       "      <td>0.978778</td>\n",
       "      <td>0.531871</td>\n",
       "      <td>0.527161</td>\n",
       "      <td>0.531871</td>\n",
       "      <td>0.525494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>638</td>\n",
       "      <td>1.018500</td>\n",
       "      <td>1.023323</td>\n",
       "      <td>0.495202</td>\n",
       "      <td>0.480621</td>\n",
       "      <td>0.495202</td>\n",
       "      <td>0.449055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.044900</td>\n",
       "      <td>0.974528</td>\n",
       "      <td>0.506511</td>\n",
       "      <td>0.521078</td>\n",
       "      <td>0.506511</td>\n",
       "      <td>0.441434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>682</td>\n",
       "      <td>0.960100</td>\n",
       "      <td>1.019100</td>\n",
       "      <td>0.514393</td>\n",
       "      <td>0.547233</td>\n",
       "      <td>0.514393</td>\n",
       "      <td>0.476783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>704</td>\n",
       "      <td>1.005300</td>\n",
       "      <td>0.964611</td>\n",
       "      <td>0.539411</td>\n",
       "      <td>0.544505</td>\n",
       "      <td>0.539411</td>\n",
       "      <td>0.513395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>726</td>\n",
       "      <td>1.040100</td>\n",
       "      <td>0.966260</td>\n",
       "      <td>0.526731</td>\n",
       "      <td>0.538041</td>\n",
       "      <td>0.526731</td>\n",
       "      <td>0.530429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>748</td>\n",
       "      <td>0.995300</td>\n",
       "      <td>0.968439</td>\n",
       "      <td>0.531871</td>\n",
       "      <td>0.537840</td>\n",
       "      <td>0.531871</td>\n",
       "      <td>0.523710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.927700</td>\n",
       "      <td>0.952058</td>\n",
       "      <td>0.538725</td>\n",
       "      <td>0.541409</td>\n",
       "      <td>0.538725</td>\n",
       "      <td>0.516269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>792</td>\n",
       "      <td>0.959200</td>\n",
       "      <td>0.952171</td>\n",
       "      <td>0.540096</td>\n",
       "      <td>0.535957</td>\n",
       "      <td>0.540096</td>\n",
       "      <td>0.535590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>814</td>\n",
       "      <td>1.015000</td>\n",
       "      <td>0.954313</td>\n",
       "      <td>0.543180</td>\n",
       "      <td>0.540623</td>\n",
       "      <td>0.543180</td>\n",
       "      <td>0.529238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>836</td>\n",
       "      <td>0.903500</td>\n",
       "      <td>0.959831</td>\n",
       "      <td>0.550377</td>\n",
       "      <td>0.550322</td>\n",
       "      <td>0.550377</td>\n",
       "      <td>0.527259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>858</td>\n",
       "      <td>0.972900</td>\n",
       "      <td>0.970410</td>\n",
       "      <td>0.525360</td>\n",
       "      <td>0.553849</td>\n",
       "      <td>0.525360</td>\n",
       "      <td>0.528460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.937400</td>\n",
       "      <td>0.940533</td>\n",
       "      <td>0.554489</td>\n",
       "      <td>0.549049</td>\n",
       "      <td>0.554489</td>\n",
       "      <td>0.546582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>902</td>\n",
       "      <td>0.943100</td>\n",
       "      <td>0.952681</td>\n",
       "      <td>0.546265</td>\n",
       "      <td>0.550871</td>\n",
       "      <td>0.546265</td>\n",
       "      <td>0.547858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>924</td>\n",
       "      <td>0.979900</td>\n",
       "      <td>0.966789</td>\n",
       "      <td>0.545236</td>\n",
       "      <td>0.559876</td>\n",
       "      <td>0.545236</td>\n",
       "      <td>0.526296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>946</td>\n",
       "      <td>0.921000</td>\n",
       "      <td>0.957445</td>\n",
       "      <td>0.538725</td>\n",
       "      <td>0.547361</td>\n",
       "      <td>0.538725</td>\n",
       "      <td>0.538490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>968</td>\n",
       "      <td>0.901900</td>\n",
       "      <td>0.941336</td>\n",
       "      <td>0.554832</td>\n",
       "      <td>0.553921</td>\n",
       "      <td>0.554832</td>\n",
       "      <td>0.549810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.962400</td>\n",
       "      <td>1.005189</td>\n",
       "      <td>0.510281</td>\n",
       "      <td>0.557942</td>\n",
       "      <td>0.510281</td>\n",
       "      <td>0.492518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1012</td>\n",
       "      <td>0.999100</td>\n",
       "      <td>1.003831</td>\n",
       "      <td>0.485607</td>\n",
       "      <td>0.572095</td>\n",
       "      <td>0.485607</td>\n",
       "      <td>0.476724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1034</td>\n",
       "      <td>0.980900</td>\n",
       "      <td>0.927411</td>\n",
       "      <td>0.571624</td>\n",
       "      <td>0.571629</td>\n",
       "      <td>0.571624</td>\n",
       "      <td>0.556207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1056</td>\n",
       "      <td>0.899700</td>\n",
       "      <td>0.926691</td>\n",
       "      <td>0.560658</td>\n",
       "      <td>0.566060</td>\n",
       "      <td>0.560658</td>\n",
       "      <td>0.523319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1078</td>\n",
       "      <td>0.971100</td>\n",
       "      <td>0.948993</td>\n",
       "      <td>0.550034</td>\n",
       "      <td>0.574898</td>\n",
       "      <td>0.550034</td>\n",
       "      <td>0.515179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.951300</td>\n",
       "      <td>0.951474</td>\n",
       "      <td>0.526731</td>\n",
       "      <td>0.566655</td>\n",
       "      <td>0.526731</td>\n",
       "      <td>0.533119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1122</td>\n",
       "      <td>0.991100</td>\n",
       "      <td>0.918947</td>\n",
       "      <td>0.564770</td>\n",
       "      <td>0.568892</td>\n",
       "      <td>0.564770</td>\n",
       "      <td>0.529419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1144</td>\n",
       "      <td>0.889600</td>\n",
       "      <td>0.956406</td>\n",
       "      <td>0.542152</td>\n",
       "      <td>0.550365</td>\n",
       "      <td>0.542152</td>\n",
       "      <td>0.510274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1166</td>\n",
       "      <td>0.890200</td>\n",
       "      <td>0.952489</td>\n",
       "      <td>0.546265</td>\n",
       "      <td>0.533298</td>\n",
       "      <td>0.546265</td>\n",
       "      <td>0.487410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1188</td>\n",
       "      <td>0.971200</td>\n",
       "      <td>0.976097</td>\n",
       "      <td>0.523304</td>\n",
       "      <td>0.575646</td>\n",
       "      <td>0.523304</td>\n",
       "      <td>0.512111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.994900</td>\n",
       "      <td>0.923849</td>\n",
       "      <td>0.568540</td>\n",
       "      <td>0.572810</td>\n",
       "      <td>0.568540</td>\n",
       "      <td>0.562681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1232</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.913097</td>\n",
       "      <td>0.576422</td>\n",
       "      <td>0.580867</td>\n",
       "      <td>0.576422</td>\n",
       "      <td>0.563618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1254</td>\n",
       "      <td>0.855400</td>\n",
       "      <td>0.909510</td>\n",
       "      <td>0.577450</td>\n",
       "      <td>0.572553</td>\n",
       "      <td>0.577450</td>\n",
       "      <td>0.572170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1276</td>\n",
       "      <td>0.940200</td>\n",
       "      <td>0.922280</td>\n",
       "      <td>0.571282</td>\n",
       "      <td>0.584268</td>\n",
       "      <td>0.571282</td>\n",
       "      <td>0.553044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1298</td>\n",
       "      <td>0.919700</td>\n",
       "      <td>0.910042</td>\n",
       "      <td>0.569911</td>\n",
       "      <td>0.580042</td>\n",
       "      <td>0.569911</td>\n",
       "      <td>0.568838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.953400</td>\n",
       "      <td>0.898706</td>\n",
       "      <td>0.584990</td>\n",
       "      <td>0.580402</td>\n",
       "      <td>0.584990</td>\n",
       "      <td>0.579470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1342</td>\n",
       "      <td>0.896900</td>\n",
       "      <td>0.964804</td>\n",
       "      <td>0.520562</td>\n",
       "      <td>0.591378</td>\n",
       "      <td>0.520562</td>\n",
       "      <td>0.523060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1364</td>\n",
       "      <td>0.975900</td>\n",
       "      <td>0.923453</td>\n",
       "      <td>0.566827</td>\n",
       "      <td>0.580950</td>\n",
       "      <td>0.566827</td>\n",
       "      <td>0.549176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1386</td>\n",
       "      <td>0.955100</td>\n",
       "      <td>0.906701</td>\n",
       "      <td>0.571967</td>\n",
       "      <td>0.587057</td>\n",
       "      <td>0.571967</td>\n",
       "      <td>0.575723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1408</td>\n",
       "      <td>0.901400</td>\n",
       "      <td>0.898895</td>\n",
       "      <td>0.583962</td>\n",
       "      <td>0.584470</td>\n",
       "      <td>0.583962</td>\n",
       "      <td>0.574133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>0.850200</td>\n",
       "      <td>0.890535</td>\n",
       "      <td>0.583276</td>\n",
       "      <td>0.588496</td>\n",
       "      <td>0.583276</td>\n",
       "      <td>0.576957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1452</td>\n",
       "      <td>0.883100</td>\n",
       "      <td>0.890539</td>\n",
       "      <td>0.582934</td>\n",
       "      <td>0.578744</td>\n",
       "      <td>0.582934</td>\n",
       "      <td>0.573093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1474</td>\n",
       "      <td>0.895300</td>\n",
       "      <td>0.927805</td>\n",
       "      <td>0.548663</td>\n",
       "      <td>0.598068</td>\n",
       "      <td>0.548663</td>\n",
       "      <td>0.554059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1496</td>\n",
       "      <td>0.858600</td>\n",
       "      <td>0.892182</td>\n",
       "      <td>0.585332</td>\n",
       "      <td>0.583677</td>\n",
       "      <td>0.585332</td>\n",
       "      <td>0.569985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1518</td>\n",
       "      <td>0.838200</td>\n",
       "      <td>0.902571</td>\n",
       "      <td>0.580877</td>\n",
       "      <td>0.578762</td>\n",
       "      <td>0.580877</td>\n",
       "      <td>0.561863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.907800</td>\n",
       "      <td>0.926284</td>\n",
       "      <td>0.581563</td>\n",
       "      <td>0.597183</td>\n",
       "      <td>0.581563</td>\n",
       "      <td>0.552584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1562</td>\n",
       "      <td>0.908300</td>\n",
       "      <td>0.903187</td>\n",
       "      <td>0.581905</td>\n",
       "      <td>0.588287</td>\n",
       "      <td>0.581905</td>\n",
       "      <td>0.578892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1584</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.917457</td>\n",
       "      <td>0.556546</td>\n",
       "      <td>0.588270</td>\n",
       "      <td>0.556546</td>\n",
       "      <td>0.561545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1606</td>\n",
       "      <td>0.865600</td>\n",
       "      <td>0.884299</td>\n",
       "      <td>0.590473</td>\n",
       "      <td>0.584962</td>\n",
       "      <td>0.590473</td>\n",
       "      <td>0.583350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1628</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>0.887634</td>\n",
       "      <td>0.593557</td>\n",
       "      <td>0.589979</td>\n",
       "      <td>0.593557</td>\n",
       "      <td>0.589329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.866300</td>\n",
       "      <td>0.892196</td>\n",
       "      <td>0.592872</td>\n",
       "      <td>0.594560</td>\n",
       "      <td>0.592872</td>\n",
       "      <td>0.591271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1672</td>\n",
       "      <td>0.871400</td>\n",
       "      <td>0.885183</td>\n",
       "      <td>0.591844</td>\n",
       "      <td>0.590446</td>\n",
       "      <td>0.591844</td>\n",
       "      <td>0.591062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1694</td>\n",
       "      <td>0.876900</td>\n",
       "      <td>0.877854</td>\n",
       "      <td>0.594243</td>\n",
       "      <td>0.589752</td>\n",
       "      <td>0.594243</td>\n",
       "      <td>0.584925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1716</td>\n",
       "      <td>0.833600</td>\n",
       "      <td>0.883420</td>\n",
       "      <td>0.595613</td>\n",
       "      <td>0.596055</td>\n",
       "      <td>0.595613</td>\n",
       "      <td>0.594636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1738</td>\n",
       "      <td>0.818900</td>\n",
       "      <td>0.883650</td>\n",
       "      <td>0.595271</td>\n",
       "      <td>0.593749</td>\n",
       "      <td>0.595271</td>\n",
       "      <td>0.581818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.872100</td>\n",
       "      <td>0.877521</td>\n",
       "      <td>0.598698</td>\n",
       "      <td>0.593803</td>\n",
       "      <td>0.598698</td>\n",
       "      <td>0.593039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1782</td>\n",
       "      <td>0.813700</td>\n",
       "      <td>0.886120</td>\n",
       "      <td>0.591501</td>\n",
       "      <td>0.594240</td>\n",
       "      <td>0.591501</td>\n",
       "      <td>0.591991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1804</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.900408</td>\n",
       "      <td>0.583619</td>\n",
       "      <td>0.587033</td>\n",
       "      <td>0.583619</td>\n",
       "      <td>0.564414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1826</td>\n",
       "      <td>0.811900</td>\n",
       "      <td>0.895421</td>\n",
       "      <td>0.579164</td>\n",
       "      <td>0.588956</td>\n",
       "      <td>0.579164</td>\n",
       "      <td>0.582251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1848</td>\n",
       "      <td>0.826100</td>\n",
       "      <td>0.897221</td>\n",
       "      <td>0.587046</td>\n",
       "      <td>0.594179</td>\n",
       "      <td>0.587046</td>\n",
       "      <td>0.580728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1870</td>\n",
       "      <td>0.897600</td>\n",
       "      <td>0.898653</td>\n",
       "      <td>0.587046</td>\n",
       "      <td>0.596796</td>\n",
       "      <td>0.587046</td>\n",
       "      <td>0.568912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1892</td>\n",
       "      <td>0.797200</td>\n",
       "      <td>0.880751</td>\n",
       "      <td>0.602125</td>\n",
       "      <td>0.597849</td>\n",
       "      <td>0.602125</td>\n",
       "      <td>0.597256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1914</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.877181</td>\n",
       "      <td>0.604524</td>\n",
       "      <td>0.600809</td>\n",
       "      <td>0.604524</td>\n",
       "      <td>0.598480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1936</td>\n",
       "      <td>0.846000</td>\n",
       "      <td>0.879154</td>\n",
       "      <td>0.607265</td>\n",
       "      <td>0.604695</td>\n",
       "      <td>0.607265</td>\n",
       "      <td>0.595411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1958</td>\n",
       "      <td>0.817800</td>\n",
       "      <td>0.876895</td>\n",
       "      <td>0.603153</td>\n",
       "      <td>0.600947</td>\n",
       "      <td>0.603153</td>\n",
       "      <td>0.592758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.874270</td>\n",
       "      <td>0.605552</td>\n",
       "      <td>0.602963</td>\n",
       "      <td>0.605552</td>\n",
       "      <td>0.598423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2002</td>\n",
       "      <td>0.836800</td>\n",
       "      <td>0.880894</td>\n",
       "      <td>0.594243</td>\n",
       "      <td>0.597893</td>\n",
       "      <td>0.594243</td>\n",
       "      <td>0.595004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2024</td>\n",
       "      <td>0.810500</td>\n",
       "      <td>0.880144</td>\n",
       "      <td>0.596642</td>\n",
       "      <td>0.603087</td>\n",
       "      <td>0.596642</td>\n",
       "      <td>0.574499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2046</td>\n",
       "      <td>0.818500</td>\n",
       "      <td>0.868723</td>\n",
       "      <td>0.611378</td>\n",
       "      <td>0.607016</td>\n",
       "      <td>0.611378</td>\n",
       "      <td>0.604685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2068</td>\n",
       "      <td>0.835700</td>\n",
       "      <td>0.871170</td>\n",
       "      <td>0.607265</td>\n",
       "      <td>0.604790</td>\n",
       "      <td>0.607265</td>\n",
       "      <td>0.600657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2090</td>\n",
       "      <td>0.836500</td>\n",
       "      <td>0.870235</td>\n",
       "      <td>0.606580</td>\n",
       "      <td>0.604381</td>\n",
       "      <td>0.606580</td>\n",
       "      <td>0.599856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2112</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.867998</td>\n",
       "      <td>0.605894</td>\n",
       "      <td>0.601791</td>\n",
       "      <td>0.605894</td>\n",
       "      <td>0.602605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2134</td>\n",
       "      <td>0.812300</td>\n",
       "      <td>0.867788</td>\n",
       "      <td>0.608979</td>\n",
       "      <td>0.604884</td>\n",
       "      <td>0.608979</td>\n",
       "      <td>0.604744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2156</td>\n",
       "      <td>0.782100</td>\n",
       "      <td>0.866864</td>\n",
       "      <td>0.611035</td>\n",
       "      <td>0.606294</td>\n",
       "      <td>0.611035</td>\n",
       "      <td>0.603592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2178</td>\n",
       "      <td>0.763700</td>\n",
       "      <td>0.867025</td>\n",
       "      <td>0.611720</td>\n",
       "      <td>0.607341</td>\n",
       "      <td>0.611720</td>\n",
       "      <td>0.602888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▃▃▃▃▃▃▃▄▅▆▅▆▆▆▅▄▆▆▆▆▇▇▇▇▇▇▇▇▇▆▇▇█▇▇███</td></tr><tr><td>eval/f1</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▅▆▆▆▆▆▇▅▆▆▇▇▇▇▆▇▇▇███▇▇██▇██</td></tr><tr><td>eval/loss</td><td>█▇▇▇▇▆▆▄▄▆▄▄▄▄▃▃▅▅▃▃▄▃▂▂▄▂▂▃▂▂▁▂▂▁▁▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▁▃▃▄▄▅▅▄▅▆▄▆▆▆▆▇▇▇▇▇▇█▇▇▇██▇▇█▇█▇██████</td></tr><tr><td>eval/recall</td><td>▁▂▂▂▂▃▃▃▃▄▄▃▅▄▅▆▆▆▆▅▇▆▅▆▆▅▆▇▇▇▇▇█▇▇▇█▇██</td></tr><tr><td>eval/runtime</td><td>▁▂▁▅▅▁▂▄▇▃▇▆▃▃▇▅▁▂▁▃▂▅▂▅▄▅▂▂▅▂▁▁▄▃▂▁▃█▅▃</td></tr><tr><td>eval/samples_per_second</td><td>█▁██▇█▇█▆▇█▇▃▇▇█▇█▆▂▁█▄▆▅▇▇▂▇▇█▆▆▅█▂▇▄▇▆</td></tr><tr><td>eval/steps_per_second</td><td>▄█▁▇█▅▆▃▅▅▇█▆▂▇▆█▆▃▇▆▇▄▇▂▄▇▄█▇▇▇▆▆▅█▆▆▇▂</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>train/grad_norm</td><td>▃█▇▆▃▃▄▇▅▅▃▇▅▂█▆▁█▅▅▆▄▂▃▆▃▃▄▂▂▅▃▂▂▃▆▄▁▃▂</td></tr><tr><td>train/learning_rate</td><td>▁▂▂▂▂▃▅▅▆▆▇▇██▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▆▇▇▇▆▇▅▅▆▅▅▅▄▄▅▄▅▃▄▃▄▅▃▄▃▃▄▂▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.61172</td></tr><tr><td>eval/f1</td><td>0.60289</td></tr><tr><td>eval/loss</td><td>0.86702</td></tr><tr><td>eval/precision</td><td>0.60734</td></tr><tr><td>eval/recall</td><td>0.61172</td></tr><tr><td>eval/runtime</td><td>3.5867</td></tr><tr><td>eval/samples_per_second</td><td>813.572</td></tr><tr><td>eval/steps_per_second</td><td>51.022</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>2190</td></tr><tr><td>train/grad_norm</td><td>5.50731</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7637</td></tr><tr><td>train_loss</td><td>0.94772</td></tr><tr><td>train_runtime</td><td>897.1718</td></tr><tr><td>train_samples_per_second</td><td>39.013</td></tr><tr><td>train_steps_per_second</td><td>2.441</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">both-ipa</strong> at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/3re1tt5k' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/3re1tt5k</a><br> View project at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250805_122951-3re1tt5k/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:47:57.533161202Z",
     "start_time": "2025-08-05T16:44:50.857217Z"
    }
   },
   "cell_type": "code",
   "source": "finetune_transcription('both', 'hin', True, model)",
   "id": "2b804266ab248bad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuning on hin ipa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/workspace/github/IPA_Finetuning/wandb/run-20250805_124451-m1adp0xh</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/m1adp0xh' target=\"_blank\">both-hin-ipa</a></strong> to <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/m1adp0xh' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/m1adp0xh</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation on hin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:00]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1346218585968018, 'eval_accuracy': 0.38333333333333336, 'eval_precision': 0.3872128265745287, 'eval_recall': 0.38333333333333336, 'eval_f1': 0.37299784555219334, 'eval_runtime': 0.9254, 'eval_samples_per_second': 194.503, 'eval_steps_per_second': 12.967, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.38333</td></tr><tr><td>eval/f1</td><td>0.373</td></tr><tr><td>eval/loss</td><td>1.13462</td></tr><tr><td>eval/precision</td><td>0.38721</td></tr><tr><td>eval/recall</td><td>0.38333</td></tr><tr><td>eval/runtime</td><td>0.9254</td></tr><tr><td>eval/samples_per_second</td><td>194.503</td></tr><tr><td>eval/steps_per_second</td><td>12.967</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>2190</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">both-hin-ipa</strong> at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/m1adp0xh' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/m1adp0xh</a><br> View project at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='184' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:05]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T13:47:57.533381947Z",
     "start_time": "2025-08-05T16:44:54.291103Z"
    }
   },
   "cell_type": "code",
   "source": "finetune_transcription('both', 'urd', True, model)",
   "id": "9f56d6f8f05af0d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuning on urd ipa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/workspace/github/IPA_Finetuning/wandb/run-20250805_124455-jhsdn2sc</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/jhsdn2sc' target=\"_blank\">both-urd-ipa</a></strong> to <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/jhsdn2sc' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/jhsdn2sc</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation on urd\n",
      "{'eval_loss': 0.8494318127632141, 'eval_accuracy': 0.6267348429510592, 'eval_precision': 0.6224711021011972, 'eval_recall': 0.6267348429510592, 'eval_f1': 0.6170482667388592, 'eval_runtime': 2.6734, 'eval_samples_per_second': 1024.18, 'eval_steps_per_second': 64.339, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.62673</td></tr><tr><td>eval/f1</td><td>0.61705</td></tr><tr><td>eval/loss</td><td>0.84943</td></tr><tr><td>eval/precision</td><td>0.62247</td></tr><tr><td>eval/recall</td><td>0.62673</td></tr><tr><td>eval/runtime</td><td>2.6734</td></tr><tr><td>eval/samples_per_second</td><td>1024.18</td></tr><tr><td>eval/steps_per_second</td><td>64.339</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>2190</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">both-urd-ipa</strong> at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/jhsdn2sc' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran/runs/jhsdn2sc</a><br> View project at: <a href='https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran' target=\"_blank\">https://wandb.ai/aaronjencks-the-ohio-state-university/debug-hindi-urdu-small-finetuning-xnli-random-initial-epitran</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250805_124455-jhsdn2sc/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f8f85719cab4b1ca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
